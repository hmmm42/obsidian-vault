一面
1. 写个LRU。
2. 一张数据库表里，一列是64位的用户id，一列是256位的用户名，两列使用频率相同，只能选一列加索引选哪个？
3. B+树、索引、索引匹配与失效一条龙。
4. 数据库同时处理两条一样的get or insert事务如何确保结果符合预期？数据库如何处理快照读和当前读？
5. Redis会有类似的问题么？怎么用Redis实现分布式锁？
6. https安全在哪？
7. tcp怎么挥手？为什么要有time_wait？
8. 调试的时候目标服务器没有响应请求，怎么排查？
### 1\. 写个LRU
LRU (Least Recently Used, 最近最少使用) 是一种经典的缓存淘汰算法. 它的核心思想是: 当缓存空间已满时, 优先淘汰掉最长时间未被使用过的数据.
要实现一个高效的 LRU Cache, 需要满足两个条件:
1.  查找 (Get) 操作要快, 最好是 O(1).
2.  插入 (Put) 和淘汰操作要快, 最好是 O(1).
结合这两个需求, 最经典的设计是使用 **哈希表 (HashMap) + 双向链表 (Doubly Linked List)**.
  * **哈希表:** 用于存储 key 到链表节点的映射, 实现 O(1) 的查找. `map[key] -> Node`.
  * **双向链表:** 用于存储数据并维护其使用顺序. 链表头部代表"最近使用", 链表尾部代表"最久未使用". O(1) 的时间复杂度即可完成节点的移动, 删除和插入操作.
下面是使用 Go 语言的实现:
```go
package main
import "container/list"
// LRUCache 定义了 LRU 缓存的结构
type LRUCache struct {
    capacity int
    cache    map[int]*list.Element // 哈希表, 存储 key 到链表节点的指针
    ll       *list.List            // Go 标准库提供的双向链表
}
// pair 是存储在链表中的实际数据结构
type pair struct {
    key   int
    value int
}
// Constructor 初始化一个 LRU 缓存
func Constructor(capacity int) LRUCache {
    return LRUCache{
        capacity: capacity,
        cache:    make(map[int]*list.Element),
        ll:       list.New(),
    }
}
// Get 获取一个值
func (this *LRUCache) Get(key int) int {
    // 1. 检查 key 是否存在于哈希表中
    if elem, ok := this.cache[key]; ok {
        // 2. 如果存在, 将该节点移动到链表头部 (表示最近使用)
        this.ll.MoveToFront(elem)
        // 3. 返回节点存储的值
        return elem.Value.(pair).value
    }
    // 4. 如果不存在, 返回 -1
    return -1
}
// Put 插入一个键值对
func (this *LRUCache) Put(key int, value int) {
    // 1. 检查 key 是否已存在
    if elem, ok := this.cache[key]; ok {
        // 2. 如果存在, 更新值, 并将其移动到链表头部
        this.ll.MoveToFront(elem)
        elem.Value = pair{key: key, value: value}
    } else {
        // 3. 如果不存在
        // 3.1 检查缓存是否已满
        if this.ll.Len() >= this.capacity {
            // 3.1.1 如果已满, 获取链表尾部节点 (最久未使用的)
            lastElem := this.ll.Back()
            if lastElem != nil {
                // 3.1.2 从链表和哈希表中删除该节点
                this.ll.Remove(lastElem)
                delete(this.cache, lastElem.Value.(pair).key)
            }
        }
        // 3.2 创建新节点, 并将其插入到链表头部
        newElem := this.ll.PushFront(pair{key: key, value: value})
        // 3.3 在哈希表中建立 key 到新节点的映射
        this.cache[key] = newElem
    }
}
```
-----
### 2\. 一张数据库表里, 一列是64位的用户id, 一列是256位的用户名, 两列使用频率相同, 只能选一列加索引选哪个?
**结论: 毫无疑问, 选择 64位的用户id (`bigint`) 加索引.**
原因如下:
1.  **索引大小:**
      * `bigint` 固定占用 8 字节.
      * `varchar(256)` (假设是 utf8mb4) 最多可能占用 `256 * 4 = 1024` 字节.
      * 索引本身也是要存储在磁盘上的, 索引越小, 占用的磁盘空间就越少. 更重要的是, 在单位内存空间 (如 InnoDB 的 Buffer Pool) 中可以缓存更多的索引页, 大大减少了磁盘 I/O, 提升查询性能.
2.  **B+树的效率:**
      * 数据库索引通常使用 B+树 实现. B+树的每个节点 (页, Page) 大小是固定的 (如 16KB).
      * 索引键越小, 每个页能存放的索引项就越多, B+树的 "扇出" (fan-out) 就越大.
      * 更大的扇出意味着 B+树的高度会更低, 更 "扁平". 查询时从根节点到叶子节点需要遍历的层级就越少, 也就是磁盘 I/O 次数更少, 查询速度更快. 这是最核心的原因.
3.  **比较效率:**
      * CPU 比较两个整数 (8字节) 的速度远快于比较两个长字符串. 字符串比较需要逐字节进行, 并且还受字符集和排序规则 (Collation) 的影响.
综上所述, 即使查询频率完全相同, 使用更小, 定长, 比较效率更高的 `bigint` 作为索引, 其性能优势也是压倒性的.
-----
### 3\. B+树、索引、索引匹配与失效一条龙
这是一个很好的问题, 串联起了数据库索引的核心知识.
1.  **B+树 (数据结构层):**
      * 首先, B+树是一种为磁盘存储优化的多路平衡查找树. 它有几个关键特点:
          * **数据只在叶子节点:** 非叶子节点只存储键值, 作为索引. 这使得非叶子节点可以存储更多的键, 增加扇出, 降低树高.
          * **叶子节点相连:** 所有叶子节点通过一个双向链表连接, 极大地提高了范围查询的效率.
          * **查询稳定:** 任何查询都必须从根走到叶, 查询路径长度一致.
      * 这个数据结构是数据库索引得以实现高性能查找和范围扫描的基石.
2.  **索引 (数据库实现层):**
      * 数据库索引就是 B+树结构的一种应用. 它是一个独立于数据表的, 用于加速查询的数据结构.
      * 在 InnoDB 中, 索引分为两种:
          * **聚簇索引 (Clustered Index):** 通常是主键. B+树的叶子节点 **直接存储了完整的数据行**. 一张表只有一个聚簇索引.
          * **二级索引 (Secondary Index):** 普通索引. B+树的叶子节点存储的是 **索引列的值和对应行的主键值**.
      * 当使用二级索引查询时, 如果需要获取未包含在索引中的列, 会先通过二级索引找到主键, 再用主键去聚簇索引中查找完整的数据行, 这个过程称为 **回表 (Key Lookup)**.
3.  **索引匹配 (生效的场景):**
      * 数据库优化器会尝试使用索引来避免全表扫描, 以下情况索引会生效:
      * **最左前缀原则 (Leftmost Prefix Principle):** 这是联合索引最重要的规则. 对于 `INDEX(a, b, c)`:
          * `WHERE a = 1` -\> 生效
          * `WHERE a = 1 AND b = 2` -\> 生效
          * `WHERE a = 1 AND b > 2` -\> a和b的部分生效, c不生效
          * `WHERE b = 2` -\> **失效** (因为没有从最左边的 a 开始)
      * **范围查询:** `WHERE a > 1`, `WHERE a BETWEEN 1 AND 10`.
      * **精确匹配:** `WHERE a = 1`.
      * **前缀匹配:** `LIKE 'abc%'` (不能是 `'%abc'`).
4.  **索引失效 (不生效的场景):**
      * **违反最左前缀原则.**
      * **对索引列使用函数或运算:** `WHERE YEAR(create_time) = 2025` 或 `WHERE score + 10 = 100`.
      * **`LIKE` 以通配符开头:** `WHERE name LIKE '%john'`.
      * **类型不一致导致隐式转换:** 索引列 `phone` 是字符串类型, 查询时写 `WHERE phone = 12345678901`, 数据库会把索引列的值转换为数字再比较, 导致索引失效.
      * **使用 `OR` , 且 `OR` 的某一侧条件没有索引.**
      * **优化器判断全表扫描更快:** 如果查询结果集占全表数据的比例很大 (例如超过20-30%), 优化器可能认为走索引+回表的成本比直接全表扫描还高, 于是放弃使用索引.
-----
### 4\. 数据库同时处理两条一样的get or insert事务如何确保结果符合预期？数据库如何处理快照读和当前读？
#### Get or Insert 问题
这是一个典型的并发问题, 也叫 "UPSERT" 或 "MERGE". 假设有两条事务 (T1, T2) 同时要插入一条 `username = 'alice'` 的记录.
**问题场景 (Race Condition):**
1.  T1: `SELECT * FROM users WHERE username = 'alice'`. (未找到)
2.  T2: `SELECT * FROM users WHERE username = 'alice'`. (未找到)
3.  T1: `INSERT INTO users (username) VALUES ('alice')`. (成功)
4.  T2: `INSERT INTO users (username) VALUES ('alice')`. (**失败**, 如果 username 有唯一约束)
**解决方案:**
5.  **使用唯一约束 + 捕获异常:**
      * 给 `username` 列添加 `UNIQUE` 索引.
      * 应用层代码直接尝试 `INSERT`. 如果成功, 万事大吉. 如果因为违反唯一约束而失败, 就捕获这个特定的异常, 然后再次执行 `SELECT` 获取已存在的数据. 这是最简单和常见的做法.
6.  **使用悲观锁 (`SELECT ... FOR UPDATE`):**
      * 在事务中, 使用 `SELECT ... FOR UPDATE` 来查询记录.
      * T1 执行 `SELECT * FROM users WHERE username = 'alice' FOR UPDATE;`. 即使记录不存在, InnoDB 也会在对应的索引范围上加上一个 **间隙锁 (Gap Lock)**, 防止其他事务在这个间隙中插入 'alice'.
      * T2 尝试执行同样的语句时, 会被阻塞, 直到 T1 提交或回滚.
      * T1 发现记录不存在后, 执行 `INSERT` 并提交. 之后 T2 才被唤醒, 再次查询时就能查到 T1 插入的记录了.
      * **优点:** 数据一致性强. **缺点:** 性能较低, 容易因锁竞争导致吞吐量下降.
#### 快照读 (Snapshot Read) vs 当前读 (Current Read)
这是 InnoDB MVCC (多版本并发控制) 机制下的两种不同读取方式.
  * **快照读 (Consistent Read):**
      * **是什么:** 读取的是事务开始时生成的数据"快照".
      * **哪些是:** 普通的 `SELECT` 语句 (在 `REPEATABLE READ` 或 `READ COMMITTED` 隔离级别下, 且不带 `FOR UPDATE` 或 `LOCK IN SHARE MODE`).
      * **如何工作:** 它通过 MVCC 机制读取undo log中的历史版本数据, 从而实现不加锁就能读取, 避免了读写冲突. 你读到的数据可能不是最新的, 但它保证了在你事务的生命周期内, 多次读取同一行数据的结果是一致的 (在 `REPEATABLE READ` 级别下).
  * **当前读 (Locking Read):**
      * **是什么:** 读取的是数据库中最新的, 已提交的版本.
      * **哪些是:**
          * `SELECT ... FOR UPDATE` (排他锁)
          * `SELECT ... LOCK IN SHARE MODE` (共享锁)
          * `INSERT`, `UPDATE`, `DELETE` (这些操作在执行前都需要先"读"到最新的数据, 然后再加锁修改)
      * **如何工作:** 当前读会给读取的记录加上锁 (共享锁或排他锁), 确保在读取和后续操作期间, 其他事务不能修改这些数据.
**总结:** 快照读为了高并发性能, 读的是历史数据; 当前读为了数据一致性 (或为了后续修改), 读的是最新数据并加锁.
-----
### 5\. Redis会有类似的问题么？怎么用Redis实现分布式锁？
#### Redis 会有类似问题吗?
**会.** Redis 同样存在并发问题. Redis 的事务 (`MULTI`/`EXEC`) 并不像关系型数据库的事务那样提供隔离性.
`MULTI` 只是告诉 Redis "我要开始一串命令了, 请把它们都加到队列里". 在 `EXEC` 执行之前, 如果有其他客户端修改了相关 key, `EXEC` 依然会继续执行队列里的命令, 只是在被修改过的数据上执行而已.
==要解决 "Get or Insert" 这种问题, Redis 通常使用 `WATCH` 命令实现乐观锁, 或者使用原子命令如 `SETNX` (Set if Not eXists).==
#### 如何用 Redis 实现分布式锁
一个健壮的分布式锁需要满足几个条件:
  * **互斥性:** 任何时刻, 只有一个客户端能持有锁.
  * **防死锁:** 即使持有锁的客户端崩溃, 锁最终也能被释放.
  * **容错性:** 只要大部分 Redis 节点正常, 客户端就能加锁和解锁.
**最常用和推荐的实现方式 (单实例 Redis):**
使用 `SET` 命令的扩展参数, 这是一个 **原子操作**:
`SET lock_key random_value NX PX 30000`
  * `lock_key`: 锁的唯一标识.
  * `random_value`: 一个随机字符串, 作为这个客户端的唯一标识. 用于安全地释放锁.
  * `NX`: (Not eXists) 只有当 `lock_key` 不存在时, `SET` 操作才会成功. 这保证了互斥性.
  * `PX 30000`: (milli-seconds) 给这个锁设置一个 30 秒的过期时间. 这保证了即使客户端崩溃, 锁也会在 30 秒后自动释放, 避免死锁.
**加锁:**
客户端尝试执行上述 `SET` 命令. 如果返回 `OK`, 则加锁成功.
**解锁:**
为了安全解锁 (防止客户端A误删了客户端B的锁), 必须使用 Lua 脚本来保证"判断-删除"的原子性.
```lua
-- Lua script for safe unlock
if redis.call("get", KEYS[1]) == ARGV[1] then
    return redis.call("del", KEYS[1])
else
    return 0
end
```
客户端调用 `EVAL` 执行这个脚本, `KEYS[1]` 是 `lock_key`, `ARGV[1]` 是加锁时设置的 `random_value`.
**为什么不能先 `GET` 再 `DEL`?** 因为这不是原子操作, 可能在 `GET` 和 `DEL` 之间, 锁已经过期并被另一个客户端获取, 此时就会误删别人的锁.
**为什么要有 `random_value`?** 防止一个客户端的业务执行时间过长, 导致锁自动过期后, 它再去释放一个已经被其他客户端获取的锁.
-----
### 6\. https安全在哪？
HTTPS (Hypertext Transfer Protocol Secure) 的安全主要体现在三个方面, 合称为 **TLS/SSL** 协议提供的安全保障:
1.  **机密性 (Confidentiality):**
      * **内容加密.** 通信双方使用对称加密算法 (如 AES) 来加密传输的所有数据. 即使网络包被中间人截获, 由于没有密钥,他也无法解密出报文的真实内容.
      * **密钥协商.** 对称加密的密钥本身是通过非对称加密算法 (如 RSA) 在初始握手阶段安全地交换的. 客户端用服务器的公钥加密一个随机数(预主密钥), 发送给服务器, 只有服务器用私钥才能解开, 然后双方根据这个随机数生成最终的会话密钥.
2.  **完整性 (Integrity):**
      * **防篡改.** 通信双方会使用一个叫做 **消息认证码 (MAC)** 的算法来为传输的数据计算一个"摘要"或"签名". 接收方会用同样的密钥和算法重新计算一遍摘要, 并与收到的摘要进行比对. 如果数据在传输过程中被篡改, 计算出的摘要就会不匹配, 接收方就会发现并丢弃该数据包.
3.  **身份认证 (Authentication):**
      * **验证服务器身份.** 这是防止钓鱼网站的关键. 服务器会向客户端出示一个由权威 **证书颁发机构 (CA)** 签发的数字证书. 你的浏览器/操作系统内置了这些权威 CA 的公钥. 浏览器会用 CA 的公钥去验证证书的签名是否有效, 并检查证书上的域名是否与你正在访问的域名一致. 这证明了你正在与之通信的服务器确实是它所声称的那个服务器, 而不是一个伪装的中间人.
简单来说, HTTPS 保证了: **你访问的网站是真网站 (身份认证), 你和网站之间说的话别人听不懂 (机密性), 也不能被篡改 (完整性).**
-----
### 7\. tcp怎么挥手？为什么要有time\_wait？
#### TCP 四次挥手 (Four-Way Handshake)
这是 TCP 断开连接的过程. 假设客户端主动发起关闭:
1.  **第一次挥手 (FIN):** 客户端的应用进程调用 `close()`, TCP 协议栈会发送一个 `FIN` (Finish) 报文给服务器, 并进入 `FIN_WAIT_1` 状态.
2.  **第二次挥手 (ACK):** 服务器收到 `FIN` 报文后, 会立即回复一个 `ACK` (Acknowledgement) 报文, 并进入 `CLOSE_WAIT` 状态. 客户端收到这个 `ACK` 后, 进入 `FIN_WAIT_2` 状态. 此时, TCP 连接处于 **半关闭** 状态, 即客户端不能再发送数据, 但服务器仍然可以向客户端发送数据.
3.  **第三次挥手 (FIN):** 当服务器也准备好关闭连接 (其应用进程也调用了 `close()`), 它会向客户端发送一个 `FIN` 报文, 然后服务器进入 `LAST_ACK` 状态.
4.  **第四次挥手 (ACK):** 客户端收到服务器的 `FIN` 报文后, 必须回复一个 `ACK` 报文. 发送完毕后, 客户端进入 **`TIME_WAIT`** 状态. 服务器收到这个 `ACK` 后, 就直接进入 `CLOSED` 状态, 连接正式关闭.
#### 为什么要有 `TIME_WAIT` 状态?
`TIME_WAIT` 状态会持续 `2 * MSL` (Maximum Segment Lifetime, 报文最大生存时间, 通常是 30秒 到 2分钟). 主动关闭连接的一方 (上例中的客户端) 会进入这个状态, 主要有两个原因:
1.  **确保最后一次 ACK 报文能够到达对方:**
      * 这是最重要的原因. 第四次挥手的 `ACK` 是由客户端发出的, 它完全可能在网络中丢失.
      * 如果服务器在 `LAST_ACK` 状态没有收到这个 `ACK`, 它会超时重传第三次挥手的 `FIN` 报文.
      * 如果此时客户端已经进入 `CLOSED` 状态, 它将不再认识这个连接, 可能会响应一个 `RST` 报文, 使服务器异常终止.
      * 而如果客户端处于 `TIME_WAIT` 状态, 它仍然保存着连接的信息, 当再次收到重传的 `FIN` 时, 就可以重新发送一次 `ACK`, 从而使服务器能够正常关闭.
2.  **防止已失效的报文段干扰新的连接:**
      * 考虑一个场景: 一个连接 `(src_ip, src_port, dst_ip, dst_port)` 刚关闭, 马上又用完全相同的四元组建立了一个新连接.
      * 此时, 网络中可能还残留着上一个"旧连接"的延迟数据包. 如果没有 `TIME_WAIT` 的等待时间, 这些旧数据包可能会被错误地当成新连接的数据来接收, 造成数据混淆.
      * `TIME_WAIT` 状态持续 `2*MSL` 的时间, 足以保证网络中所有与旧连接相关的报文都已经自然消失, 从而确保新连接不会受到干扰.
-----
### 8\. 调试的时候目标服务器没有响应请求，怎么排查？
这是一个考察系统性思维和网络基础的经典开放题. 排查应遵循 **由近及远, 从底层到上层** 的原则.
**1. 本地客户端排查:**
  * **问题复现:** 确认问题是稳定复现还是偶发.
  * **错误信息:** 查看客户端的报错信息是什么? 是 "Connection refused", "Connection timed out", 还是 "Name or service not known"? 不同的错误指向不同的问题方向.
  * **换个环境:** 问问同事是否能访问, 或者使用 `curl` 等简单工具在自己机器上尝试, 排除是自己应用代码的问题.
**2. 网络连通性排查 (从客户端到服务器):**
  * **DNS 解析:** `ping target-server.com`. 看是否能解析到正确的 IP 地址. 如果不能, 使用 `nslookup` 或 `dig` 排查 DNS 问题.
  * **网络可达性:** `ping <服务器IP>`. 如果 ping 不通, 可能是服务器禁 ping, 或者中间网络 (路由器, 防火墙) 有问题.
  * **端口连通性:** 这是最关键的一步. `telnet <服务器IP> <端口号>` (例如 `telnet 1.2.3.4 8080`) 或者 `nc -zv <服务器IP> <端口号>`.
      * 如果显示 "Connected", 说明网络是通的, 应用也在监听端口. 问题在应用层.
      * 如果显示 "Connection refused", 说明网络是通的, 但服务器上没有进程在监听这个端口.
      * 如果没有任何反应直到超时 ("Connection timed out"), 说明你和服务器之间的网络被防火墙 (公司防火墙, 云服务商安全组, 服务器自身防火墙) 拦截了.
**3. 服务器端排查 (登录到服务器上):**
  * **进程是否在运行?** `ps aux | grep my_app` 或 `systemctl status my_app` 查看应用进程是否存在且状态正常.
  * **端口是否在监听?** `netstat -tulnp | grep <端口号>` 或 `ss -tulnp | grep <端口号>`.
      * 确认进程确实在监听你请求的那个端口.
      * **特别注意监听的IP\!** 是 `0.0.0.0:<端口>` (监听所有网卡), 还是 `127.0.0.1:<端口>` (只监听本地回环地址)? 后者会导致外部无法访问, 这是新手常犯的错误.
  * **服务器防火墙:** `iptables -L -n` 或 `firewall-cmd --list-all`. 检查服务器自身的防火墙规则是否放行了该端口.
  * **系统资源:**
      * `top` / `htop`: CPU 是否 100%, 导致无法处理新请求?
      * `free -h`: 内存是否耗尽, 导致 OOM (Out Of Memory)? `dmesg | grep -i oom` 查看是否有进程被系统杀死.
      * `df -h`: 磁盘空间是否已满? (日志文件可能会写满磁盘, 导致应用无法写入新日志而夯住).
      * `lsof -p <PID> | wc -l`: 文件描述符是否耗尽? `ulimit -n` 查看限制.
**4. 应用层排查:**
  * **查看日志\! 查看日志\! 查看日志\!** `tail -f /path/to/app.log`. 查看应用日志, 错误日志, access log. 有没有报错信息, 异常堆栈?
  * **依赖服务:** 应用是否依赖了其他服务 (如数据库, Redis)? 检查应用到这些依赖服务的连接是否正常. 可能你的应用因为连不上数据库而卡住了.
通过以上由表及里, 层次分明的排查, 绝大多数 "无响应" 问题都能被定位., 我们继续. 这第二批问题更加深入, 考察了算法实现, 数据库底层原理, 分布式系统以及网络和排错实践, 是非常好的进阶面试题.
二面
9. 实习写过Rust跟C++，为什么喜欢Go？Go你喜欢它哪里？简单讲一下协程？
10. C++的内存问题怎么排查的？
11. 聊实习，遇到的困难？做业务的哪个环节最麻烦？
12. 数据库主从同步？从库同步过程是单线程执行命令么？会不会有跟主库执行顺序不一致的问题？
13. 数据库查询怎么加锁？
14. 数据库cpu占用高什么原因？机器里各个指标占用高分别怎么排查，有用过从整个程序里定位问题代码的工具么？
15. Redis数据类型，讲一下跳表？
16. tcp连接大量time_wait什么情况？
17. 设计一个外卖秒杀系统，怎么处理短时大流量？
18. 最近一年用了哪些ai工具，比较熟悉哪家的什么模型？写过prompt么？什么时候用思维链模型？
19. 最近在看什么书？有在学什么技术么？有自己写过什么小玩意么？
### 9. 实习写过Rust跟C++, 为什么喜欢Go？Go你喜欢它哪里？简单讲一下协程？
这是一个很好的问题, 它在考察你的技术选型思考能力, 而不是语言的“宗教战争”. 一个好的回答应该体现出对不同语言设计哲学的理解和尊重.
**回答思路:**
“我在实习中深入使用了 C++ 和 Rust, 对它们的强大性能和底层控制能力有很深的体会. C++ 是工业界的基石, 生态无人能及; Rust 则通过其所有权系统在编译期解决了内存安全这一大痛点, ‘无畏并发’ 的理念非常吸引人.
之所以在很多后端服务场景下我更偏爱 Go, 主要基于以下几点, 我认为它找到了一个非常巧妙的平衡点:
1. **极简的哲学与工程效率:** Go 的语法非常简洁, 规范统一, 学习曲线平缓. 这在大型团队协作中是巨大的优势, 它使得代码的可读性和可维护性非常高, 新人也能快速上手并写出风格一致的代码. 相比之下, C++ 的复杂性和“茴”字有多种写法的特点, 长期维护成本更高.
2. **为网络与并发而生的语言:** Go 的杀手级特性无疑是它的并发模型. Goroutine 和 Channel 的设计, 让编写高并发的程序变得前所未有的简单和直观. 你不需要像 C++ 那样手动管理线程, 担心锁的各种问题. "不要通过共享内存来通信, 而要通过通信来共享内存" 这个理念从根本上降低了并发编程的心智负担.
3. **务实的工程设计 (Pragmatism):**
    - **编译速度:** Go 的编译速度极快, 这带来了非常流畅的开发体验 (改动 -> 编译 -> 测试).
    - **垃圾回收 (GC):** Go 选择了带 GC. 对于绝大多数后端业务来说, GC 带来的开发便利性远超其微小的性能开销. 它让我们专注于业务逻辑, 而不是手动内存管理. 这是 Go 与 Rust/C++ 的一个关键取舍, 我认为对于业务开发是正确的取舍.
    - **强大的标准库和工具链:** `net/http`, `pprof` 等标准库质量非常高, "开箱即用". 工具链 (testing, formatting, linting) 的统一也提升了开发规范.
**简单讲一下协程:**
Goroutine 就是 Go 语言实现的协程. 你可以把它理解为一种比线程更轻量的, 用户态的"线程".
- **轻量:** 一个 Goroutine 的初始栈空间只有 2KB 左右, 而一个线程通常是几 MB. 所以可以轻松创建成千上万个 Goroutine.
- **调度:** 它不由操作系统内核直接调度, 而是由 Go 语言自己的运行时 (Runtime) 来调度. 这个调度器非常高效, 它会将 M 个 Goroutine "复用" N 个操作系统线程 (M:N模型), 切换成本极低, 因为不涉及内核态的切换.
- **通信:** Goroutine 之间推荐使用 `channel` 来进行安全的数据交换和同步, 这也是 Go 并发哲学的体现.”
---
### 10. C++的内存问题怎么排查的？
排查 C++ 的内存问题需要一个工具和方法的组合拳, 主要分为静态分析和动态分析.
1. **静态分析 (编码和编译阶段):**
    - **遵循良好实践:** 使用现代 C++ 的 RAII (资源获取即初始化) 思想, 优先使用智能指针 (`std::unique_ptr`, `std::shared_ptr`) 来管理动态分配的内存, 避免裸 `new` 和 `delete`.
    - **编译器警告:** 开启并重视编译器的警告, 如 `g++ -Wall -Wextra`.
    - **静态分析工具:** 使用 Clang-Tidy 等工具在编码时就对代码进行扫描, 发现潜在的内存问题.
2. **动态分析 (运行和调试阶段):**
    - **Valgrind (尤其是 Memcheck 工具):** 这是 Linux 下的内存问题排查神器. 它能检测出:
        - **内存泄漏 (Memory Leak):** 分配了内存但从未释放.
        - **非法访存:** 读写已经释放的内存 (Use-After-Free), 数组越界读写 (Buffer Overflow) 等.
        - **使用未初始化的内存.**
        - **重复释放 (Double Free).**
        - **缺点:** 运行速度很慢 (通常会慢 10-30 倍), 因为它是在一个模拟 CPU 上执行你的程序.
    - **AddressSanitizer (ASan):** 一个由 Google 开发的, 集成在编译器 (GCC, Clang) 中的工具. 通过编译时插桩 (`-fsanitize=address`) 来检测内存问题.
        - **优点:** 性能远高于 Valgrind (通常只慢 2 倍左右), 是现代 C++ 开发中排查内存问题的首选.
        - **原理:** 它在每次内存分配的周围设置了 "毒药区" (Redzone), 如果代码访问到了这些区域, 就会立即报错. 它也能检测大部分 Valgrind 能检测的问题.
    - **调试器 (GDB):** 对于已知的崩溃, 可以使用 GDB 加载 `core dump` 文件来分析崩溃时的内存状态, 查看调用栈, 检查变量值, 定位问题根源.
---
### 11. 聊实习，遇到的困难？做业务的哪个环节最麻烦？
这是一个开放性问题, 旨在考察你的解决问题能力, 沟通能力和反思能力. 建议使用 **STAR 法则 (Situation, Task, Action, Result)** 来组织回答.
**回答范例:**
遇到的困难:
"实习期间我遇到的一个比较大的挑战是, 在一个庞大且复杂的现有项目中添加一个新功能.
- **(Situation/Task):** 我需要开发一个新的 API, 它依赖了几个内部的微服务, 并且需要修改一个核心模块的计费逻辑.
- **(Action):** 起初我有些无从下手. 我的做法是: 首先, 我花了大量时间通读相关模块的代码和文档, 并使用调试器单步跟踪了几个关键的业务流程, 以理解代码的执行逻辑. 其次, 我主动找到我的 Mentor, 和他约定时间一起做了一次 Code Review, 他帮我梳理了核心的数据流和需要注意的边界情况. 最后, 对于不确定的需求细节, 我整理成文档并主动与产品经理沟通确认.
- **(Result):** 通过这种方式, 我不仅顺利地完成了功能开发和上线, 还因为对模块的深入理解, 在后续排查一个线上问题时快速定位到了原因. 这让我明白了, 融入一个复杂项目, 主动沟通和花时间深入理解上下文是非常重要的."
做业务的哪个环节最麻烦:
"我认为做业务最麻烦的环节往往不是编码本身, 而是 需求澄清和跨团队协作.
- **需求澄清:** 很多时候, 产品经理提出的初始需求可能只描述了理想情况, 但会缺少对各种异常情况, 边界条件和未来扩展性的考虑. 作为开发, 我们需要反复地追问 '如果...会怎样?', 帮助产品把需求细化得足够清晰, 避免上线后才发现逻辑漏洞.
- **跨团队协作:** 一个功能的上线通常需要前后端, 测试, 运维等多个团队的配合. 比如定义清晰的 API 契约, 协调联调和发布的时间窗口, 确保上下游的理解一致. 这个过程中的沟通成本有时甚至会超过开发本身, 它非常考验一个工程师的沟通能力和项目推动能力."
---
### 12. 数据库主从同步？从库同步过程是单线程执行命令么？会不会有跟主库执行顺序不一致的问题？
主从同步原理 (以 MySQL 为例):
MySQL 的主从同步主要依赖于 binlog (二进制日志).
1. **主库 (Master):** 当主库执行一个写操作 (INSERT, UPDATE, DELETE) 时, 它会把这个操作的“事件 (event)” 记录到自己的 binlog 文件中.
2. **从库 I/O 线程:** 从库上有一个 I/O 线程, 它会连接到主库, 请求主库的 binlog. 当主库产生新的 binlog 事件时, 会传送给从库的 I/O 线程.
3. **从库 Relay Log:** I/O 线程接收到 binlog 事件后, 会将其写入到从库本地的一个叫做 **中继日志 (Relay Log)** 的文件中.
4. **从库 SQL 线程:** 从库上还有另一个 SQL 线程, 它会读取 Relay Log 中的事件, 并在从库上 **重放 (replay)** 这些 SQL 操作, 从而使从库的数据与主库保持一致.
**从库同步是单线程吗?**
- **过去是:** 在 MySQL 5.5 及之前的版本, SQL 线程确实是单线程的. 这是主从延迟 (Replication Lag) 的一个主要瓶颈. 如果主库并发写入量很大, 单一的 SQL 线程可能执行不过来.
- **现在不是了:** 从 MySQL 5.6 开始, 引入了 **并行复制 (Parallel Replication)**. 从库可以开启多个 SQL 线程 (Worker 线程) 来并行地执行 Relay Log 中的事务. 并行策略包括按库并行, 或者在 5.7 版本后引入的, 基于 `LOGICAL_CLOCK` 的更智能的并行复制, 它可以让没有数据冲突的事务在从库上并发执行.
会不会有执行顺序不一致的问题?
不会. 数据库通过严谨的机制保证了从库的执行顺序与主库的逻辑顺序是一致的.
- **binlog 是有序的:** 主库上的事务是按提交顺序写入 binlog 的. 这个顺序是确定的.
- **并行复制的安全性:** 即使在并行复制模式下, 也不是随便并行执行的. 调度器 (Coordinator 线程) 会分析 Relay Log 中的事务依赖关系. 只有那些在主库上可以并行执行 (即没有锁冲突) 的事务, 才会在从库上被分发到不同的 Worker 线程去并行执行. 如果两个事务在主库上有依赖关系, 它们在从库上也一定会被串行执行.
因此, 最终的数据状态能够保证和主库一致.
---
### 13. 数据库查询怎么加锁？
在事务中, 我们可以通过特定的 `SELECT` 语法来显式地为读取的数据行加锁. 这主要分为两种锁:
1. **共享锁 (Shared Lock / S-Lock):**
    - **语法:** `SELECT ... LOCK IN SHARE MODE;` (在一些老版本中是 `SELECT ... FOR SHARE;`)
    - **作用:** 对读取的行加上一个共享锁.
    - **行为:**
        - 其他事务 **可以** 读取这些加了锁的行 (也可以再加共享锁).
        - 其他事务 **不能** 修改或删除这些行 (即无法获取排他锁), 必须等待当前事务释放共享锁.
    - **使用场景:** 当你读取数据, 并且不希望这些数据在你事务提交前被其他事务修改, 但你不在乎别人读取它. 比如, 你要插入一个子表记录, 需要先查询父表记录是否存在, 你可以用共享锁锁住父表记录, 防止在你插入子表记录期间父表记录被删除.
2. **排他锁 (Exclusive Lock / X-Lock):**
    - **语法:** `SELECT ... FOR UPDATE;`
    - **作用:** 对读取的行加上一个排他锁.
    - **行为:**
        - 其他事务 **既不能** 读取 (无法再加任何锁, 包括共享锁), **也不能** 修改或删除这些行.
        - 其他任何想要对这些行操作的事务都会被阻塞, 直到当前事务提交或回滚.
    - **使用场景:** 当你读取数据, 并且打算在稍后的同一个事务中去修改或删除它时. 这可以防止多个事务同时读取同一行数据, 然后都尝试去修改, 从而引发的并发问题 (第二类丢失更新). 这是悲观锁的典型实现.
---
### 14. 数据库cpu占用高什么原因？机器里各个指标占用高分别怎么排查，有用过从整个程序里定位问题代码的工具么？
#### 数据库 CPU 占用高的原因
1. **大量慢查询:** 存在很多没有走到索引的查询 (全表扫描), 或者有复杂文件排序 (filesort), 临时表操作的查询.
2. **高并发:** QPS (每秒查询率) 过高, 即使单个查询很快, 大量查询的累积效应也会耗尽 CPU.
3. **锁等待:** 大量事务因锁冲突而等待, 数据库调度和管理这些等待状态也消耗 CPU.
4. **计算密集型操作:** 在数据库中执行了复杂的函数, 聚合运算等.
#### 各项指标过高排查思路
- **CPU 过高:**
    - **数据库:** 使用 `SHOW FULL PROCESSLIST;` 查看当前正在执行的线程和 SQL. 找到那些 `Time` 很长的查询. 对可疑的慢查询执行 `EXPLAIN`, 分析它的执行计划, 看是否用上了索引. 开启慢查询日志 (slow query log) 来捕获和分析慢 SQL.
    - **应用程序:** 使用 Profiling 工具.
- **内存过高:**
    - **数据库:** 检查 InnoDB Buffer Pool, `tmp_table_size`, `max_heap_table_size` 等配置是否过大.
    - **应用程序:** 使用内存分析工具, 检查是否存在内存泄漏.
- **磁盘 I/O 过高:**
    - **数据库:** 使用 `iostat`, `iotop` 等工具查看是哪个进程在大量读写. 通常是由于查询无法利用内存中的索引或数据 (Buffer Pool 命中率低), 导致频繁从磁盘读取数据页.
    - **应用程序:** 检查是否在大量写日志, 或者有其他频繁的文件操作.
#### 定位问题代码的工具
**当然用过, Go 语言在这方面有非常强大的内置工具: `pprof`.**
`pprof` 是 Go 语言的性能分析工具, 它可以从正在运行的程序中采样数据, 帮助我们定位性能瓶颈.
1. **引入:** 只需在代码中匿名导入 `net/http/pprof` 包, 它就会自动注册 HTTP 接口.
2. **CPU 分析:**
    - 在浏览器或通过 `curl` 访问 `http://<host>:<port>/debug/pprof/profile?seconds=30`.
    - 这会进行 30 秒的 CPU 采样, 生成一个 profile 文件.
    - 使用 `go tool pprof <profile_file>` 就可以进入交互式命令行进行分析.
    - 输入 `top` 可以看到 CPU 占用最高的函数列表.
    - 输入 `web` 可以生成一张 **火焰图 (Flame Graph)** 或调用关系图, 非常直观地展示出哪个函数调用链消耗了最多的 CPU 时间, 从而快速定位到问题代码.
3. **内存分析:**
    - 访问 `http://.../debug/pprof/heap` 获取堆内存分配的 profile.
    - 同样使用 `go tool pprof` 分析, 可以看到哪些代码路径分配了最多的内存, 用于排查内存泄漏或不合理的内存使用.
`pprof` 是 Go 开发者的必备技能, 它能高效地从宏观的"CPU占用高"指标, 精准定位到微观的某几行问题代码.
---
### 15. Redis数据类型，讲一下跳表？
**Redis 常用数据类型:**
- **String:** 最基础的类型, 可以是字符串, 数字或二进制数据. 用于缓存, 计数器等.
- **List:** 有序的字符串列表. 可用作队列或栈.
- **Hash:** 键值对集合, 适合存储对象.
- **Set:** 无序, 唯一的字符串集合. 用于标签, 去重等.
- **Sorted Set (ZSet):** Set 的升级版, 每个成员都关联一个分数 (score), 集合根据分数排序.
讲一下跳表 (Skip List):
跳表是 Sorted Set (有序集合) 的底层实现之一 (当元素较多时). 它是一种通过空间换时间思想设计出来的, 能够实现快速查找的概率性数据结构.
核心思想:
你可以把跳表想象成一个有多层"快车道"的普通链表.
1. **基础层 (Level 0):** 是一个标准的有序链表, 包含所有元素.
2. **多级索引:** 在基础层之上, 有多个"索引"层. 每一层都是下一层链表的一个稀疏子集. 一个元素有一定概率 (如 1/4) 同时出现在更高一层的索引中.
3. **查找过程:**
    - 从最高层的链表开始查找.
    - 在当前层, 向前遍历, 直到找到的下一个节点大于或等于目标值.
    - 然后从当前节点下降一层, 继续向前查找.
    - 重复这个过程, 直到到达最底层, 就能快速定位到目标元素或其插入位置.
**为什么 Redis 用跳表?**
- **效率高:** 插入, 删除, 查找的时间复杂度平均都是 O(logN), 和平衡树相当.
- **实现简单:** 相较于红黑树等复杂的平衡树, 跳表的实现和调试要简单得多.
- **范围查询友好:** 因为其底层是链表, 所以进行范围查询 (如 `ZREVRANGEBYSCORE`) 的效率很高.
- **并发控制简单:** 在并发场景下, 跳表对局部节点的修改影响范围小, 锁的粒度可以更细.
---
### 16. tcp连接大量time_wait什么情况？
当服务器上出现大量 `TIME_WAIT` 状态的 TCP 连接时, 通常意味着 **这台服务器作为客户端, 主动发起了大量的短连接请求.**
**回忆一下四次挥手:** 是主动关闭连接的一方, 最终会进入 `TIME_WAIT` 状态.
#### 原因
- 任意一方没有用长连接
- 长连接超时
- 一个长连接内的请求数达到上限
**常见场景:**
- 一台 Web 服务器频繁地去请求后端的数据库 (如 Redis, MySQL) 或其他微服务.
- 这台服务器上的爬虫程序在大量抓取网页.
- 一个负载均衡器 (如 Nginx) 作为客户端去连接后端的 Real Server.
**为什么这是个问题?**
- `TIME_WAIT` 状态会占用一个端口号和一些内核内存.
- 一个机器的可用端口号是有限的 (约几万个).
- 如果短连接的创建速度超过了 `TIME_WAIT` 状态的释放速度 (通常是 1-4 分钟), 就会耗尽所有可用的端口号, 导致新的出站连接无法建立, 报 "address already in use" 的错误.
**如何解决?**
1. **治本之道: 使用长连接/连接池.**
    - 这是最佳方案. 不要为每个请求都建立一个新的 TCP 连接.
    - 对于 HTTP 请求, 开启 **HTTP Keep-Alive**.
    - 对于数据库连接, 使用 **数据库连接池**.
    - 这样可以复用已建立的连接, 从根本上避免大量短连接的创建和关闭.
2. **调整内核参数 (治标, 需谨慎):**
    - `net.ipv4.tcp_tw_reuse = 1`: 允许将 `TIME_WAIT` 状态的 socket 用于新的 TCP 连接. 这个参数相对安全, 可以开启.
    - `net.ipv4.tcp_tw_recycle = 1`: (已废弃, **不要用!**) 更激进地回收 `TIME_WAIT` socket, 在 NAT 环境下会导致严重问题.
    - `net.ipv4.tcp_fin_timeout = 30`: 缩短 `TIME_WAIT` 的等待时间. 这违反了 TCP 协议的设计初衷, 可能导致旧连接的数据包干扰新连接, 存在风险.
---
### 17. 设计一个外卖秒杀系统，怎么处理短时大流量？
这是一个经典的系统设计题. 核心思想是 **分层过滤, 异步处理, 牺牲部分一致性来换取核心业务的可用性.**
**挑战:** 流量瞬时非常大, 而数据库的处理能力是有限的, 必须保护数据库不被打垮.
**设计方案:**
1. **前端/客户端层:**
    - **页面静态化:** 商品详情页尽可能做成静态页面, 部署到 CDN, 减少对后端服务器的动态请求.
    - **按钮控制:** 秒杀开始前, "抢购" 按钮置灰. 通过前端定时器在秒杀开始时激活按钮, 避免用户提前无效点击.
    - **请求限流:** 前端可以做一些简单的请求频率限制, 比如点击一次后按钮禁用几秒.
2. **接入层 (Nginx/Gateway):**
    - **流量整形 (Traffic Shaping):** 在网关层设置限流策略, 如使用 **令牌桶 (Token Bucket)** 算法, 只允许一部分真正有效的流量进入后端系统. 多余的请求直接返回"活动火爆, 请稍后再试"的友好提示.
    - **过滤恶意请求:** 识别并拦截黄牛, 爬虫的请求.
3. **应用服务层 (核心):**
    - **缓存! 缓存! 缓存!** 这是应对读流量的核心.
        - **数据预热:** 秒杀开始前, 将商品信息, **特别是库存数量**, 加载到分布式缓存中 (如 Redis).
        - **读请求走缓存:** 所有对商品信息的读取请求, 全部命中 Redis, 完全不穿透到数据库.
    - **库存扣减在 Redis 中完成 (核心中的核心):**
        - **原子操作:** 利用 Redis 的 `DECR` 或 `DECRBY` 命令来扣减库存. 这是一个原子操作, 能保证在高并发下库存数据不会出错.
        - **库存预判:** 如果 `DECR` 返回的结果小于 0, 说明库存已售罄, 后续的用户请求直接返回"已售罄"即可, 不再进入后续流程.
4. **业务解耦与异步化:**
    - **使用消息队列 (Message Queue):**
        - 当用户在 Redis 中成功扣减库存后 (抢到了资格), **不要马上在数据库里创建订单**.
        - 而是生成一个包含 `userId` 和 `productId` 的消息, 把它扔进 **消息队列** (如 Kafka, RocketMQ) 中. 此时就可以立即给用户返回一个 "排队中/抢购成功, 正在为您生成订单" 的友好提示.
    - **异步订单处理:**
        - 有一个独立的订单服务, 作为消费者去消息队列里拉取消息.
        - 这个服务按照自己的节奏, 平稳地, 慢慢地在数据库中创建真实的订单记录.
        - 这样就把秒杀瞬间的流量洪峰, "削峰填谷", 变成了平稳的数据库写入操作.
**数据一致性:**
- 这个方案牺牲了强一致性. 比如, 在 Redis 中扣减了库存, 但后续创建订单失败了怎么办? 需要有 **补偿机制**, 比如记录失败日志, 后续进行库存的回补, 或者进行人工处理.
**总结:** 通过 CDN 和网关挡住大部分无效流量, 通过 Redis 缓存处理绝大部分读请求和核心的写请求 (库存), 再通过消息队列将后续的数据库操作异步化, 实现了对后端数据库的完美保护.
---
### 18. 最近一年用了哪些ai工具，比较熟悉哪家的什么模型？写过prompt么？什么时候用思维链模型？
**回答思路:** 展现你对 AI 领域的关注和实践, 而不仅仅是普通用户.
"在过去一年里, 我主要使用了两类 AI 工具.
- **编码辅助:** **GitHub Copilot** 是我日常写代码时离不开的工具. 它在代码补全, 编写单元测试, 以及快速实现一些模板代码方面极大地提升了我的效率.
- **API 调用与模型研究:** 我对 **OpenAI 的模型** 比较熟悉, 主要是通过其 API 进行调用和实验. 我熟悉 `GPT-3.5-Turbo` 和 `GPT-4` 模型的区别和各自的适用场景. `GPT-3.5` 响应速度快, 成本低, 适合做一些聊天, 文本分类等要求不高的任务. `GPT-4` 的逻辑推理能力更强, 遵循指令的能力也更好, 适合用在需要复杂分析和高质量内容生成的场景.
关于 Prompt:
"是的, 我写过很多 prompt. 我认为 prompt engineering 是有效使用大模型的关键. 我会根据不同的任务设计不同的 prompt, 比如:
- **角色扮演 (Role-playing):** `"You are a senior Go developer. Please review the following code..."`, 这能让模型以更专业的视角输出内容.
- **零样本/少样本 (Zero-shot/Few-shot):** 在 prompt 中提供一两个示例, 能让模型更好地理解我想要的输出格式和风格.
关于思维链 (Chain of Thought, CoT):
"我通常在处理需要 多步推理 的复杂问题时, 会明确地在 prompt 中要求模型使用思维链. 比如:
- **解决一个算法题:** 我会要求它 `Let's think step by step.` (让我们一步一步地思考), 先分析问题, 再设计思路, 最后写代码.
- **调试一个复杂的 Bug:** 我会让它先分析日志, 推断可能的原因, 然后逐一验证这些可能性.
使用 CoT 的好处是, 它强迫模型放慢'思考'速度, 把一个复杂问题分解成多个简单的子问题. 这不仅能显著提高最终答案的准确率, 而且它的推理过程是可见的, 这对于我们理解和验证它的逻辑非常有帮助."
---
### 19. 最近在看什么书？有在学什么技术么？有自己写过什么小玩意么？
这个问题是考察你的学习主动性, 技术热情和好奇心.
**回答范例:**
- **在看的书:** "我最近在看马丁·克勒普曼的 **《设计数据密集型应用》(DDIA)**. 这本书非常经典, 它系统性地讲解了分布式系统中关于数据存储, 复制, 分区, 事务等核心概念. 它帮助我把日常工作中使用的数据库, 缓存, 消息队列等工具背后的原理串联起来, 让我对整个后端技术体系有了更深刻的理解." (Tip: 提一本业内公认的好书, 并说明它带给你的思考).
- **在学的技术:** "最近我对 **eBPF** 技术比较感兴趣. 它能够在不修改内核代码的情况下, 安全地在内核空间运行自定义的程序, 这在网络, 安全和可观测性领域有巨大的应用潜力. 比如像 Cilium, Pixie 这些项目都是基于 eBPF 实现的, 我正在学习它如何被用来构建高效的服务网格和监控系统." (Tip: 提一个有深度且前沿的技术, 显示你的技术视野).
- **写的小玩意:** "是的, 我自己用 Go 写了一个简单的 **分布式ID生成器**. 它模拟了雪花算法 (Snowflake) 的思想, 使用 '时间戳 + 机器ID + 序列号' 来生成全局唯一的 ID. 在这个过程中, 我实践了如何处理时钟回拨问题, 以及如何通过 Redis 来分配和管理机器 ID, 算是一个把分布式系统理论应用到实践中的小练习." (Tip: 准备一个能讲清楚技术细节的小项目, 不求复杂, 但求能体现你的思考).