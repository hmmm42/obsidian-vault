分享一下oc面经
# 一面
自我介绍
介绍一下业务项目，讲一下抢购流程和项目难点
1500的QPS是怎么设计的
用什么工具进行压测
压测的这些请求是一样的还是按照一定规则变化
了解限流吗，项目里有实现吗
go中什么数据结构是值拷贝，引用拷贝。
讲一下slice和数组
为什么go要引入slice和数组
goroutine中只能用channel的，什么联系
goroutine中怎么用锁的
讲一下go的泛型
讲一下go的接口
讲一下了解的设计模式，讲了策略模式
用过什么数据库，讲了Redis和MySQL
MySQL和Redis的区别，它们的技术选型，应用场景，讲讲理解
讲解对MySQL索引的理解
有没有用过elasticsearch(只了解过)
共享本地ide手撕反转链表
http和tcp的区别
开始比较随便的问题
有没有用过腾讯云或者阿里云
有没有用过k8s
有没有用过docker
项目怎么部署服务的，docker部署有什么优势
有没有用什么ai辅助编程
最近在读什么书
是打算本科毕业还是读研深造
反问

### 介绍一下业务项目, 讲一下抢购流程和项目难点
“好的. 在我之前的实习中, 我核心参与了一个电商平台的 **高并发秒杀/抢购系统** 的后端开发.
**业务目标** 是为运营活动提供一个能够支撑瞬时大流量的商品抢购功能. 用户可以在指定时间点进入活动页面, 对限量商品进行抢购, 先到先得.
**核心抢购流程** 是一个经过精心设计的, 层层过滤的体系:
1. **前端引导与静态化:** 用户首先访问的活动页面是高度静态化的, 内容被部署在 CDN 上, 减少了对我们后端服务器的直接压力. 抢购按钮在活动开始前是置灰的.
2. **流量接入与限流:** 当用户点击抢购按钮, 请求首先到达我们的 API 网关. 网关层部署了 **令牌桶限流** 策略, 它会直接拦截掉超出系统处理能力的请求, 返回‘活动火爆, 请稍后再试’的友好提示.
3. **库存预检与扣减 (核心):** 通过了网关的请求会进入到我们的 Go 应用服务层. 这一层 **不会直接查询数据库**, 而是访问 **Redis 缓存**. 我们在秒杀前已将商品库存预热到 Redis 中. 服务会直接在 Redis 中使用 `DECR` 原子命令扣减库存. 如果 `DECR` 后的值小于0, 说明已售罄, 直接返回抢购失败.
4. **异步创建订单:** 如果 Redis 库存扣减成功, 我们认为用户已经‘抢购成功’. 此时, 我们 **不会同步地在数据库中创建订单**, 因为这会拖垮数据库. 相反, 我们会将包含 `userId` 和 `productId` 的订单信息作为一个消息, 发送到 **Kafka 消息队列** 中. 然后立刻给用户返回一个‘抢购成功, 订单处理中’的响应.
5. **订单服务消费:** 有一个独立的订单服务集群, 作为消费者, 以自己平稳的节奏从 Kafka 中拉取消息, 慢慢地, 异步地将订单数据持久化到 MySQL 数据库中.
**项目难点:**
6. **保护数据库不被瞬时流量打垮:** 这是最大的难点. 整个设计的核心就是为了避免流量直接冲击 MySQL. 我们通过 CDN, 网关限流, Redis 缓存和 Kafka 消息队列构建了四层保护.
7. **Redis 库存的原子性与数据一致性:** 必须使用原子命令 (`DECR`) 来避免超卖. 同时, 如果后续异步创建订单失败 (比如用户账户异常), 还需要有补偿机制来回滚 Redis 库存.
8. **分布式环境下的高可用:** 整个系统都是无状态和水平扩展的. 限流, 库存扣减等都依赖于集中的分布式组件 (Redis), 需要保证这些组件的高可用.
9. **接口的防刷与安全:** 需要在网关和业务逻辑中加入风控逻辑, 识别并拦截来自机器人或脚本的恶意请求.”
---
### 1500的QPS是怎么设计的
“设计 1500 QPS 的目标, 核心在于将压力从慢速的磁盘 IO (数据库) 转移到高速的内存 IO (缓存和消息队列), 并通过水平扩展来分散负载.
1. **瓶颈定位:** 我们首先分析, 抢购的瓶颈在于‘库存扣减’这一步, 它要求强一致性和极高的处理速度. 传统的数据库 `UPDATE ... WHERE stock > 0` 扛不住这个并发量.
2. **核心组件选型:** 我们选择了 **Redis** 作为库存扣减的核心组件. 单实例 Redis 对简单命令 (如 `DECR`, `GET`) 的处理能力可以轻松达到数万甚至十万 QPS, 1500 QPS 对它来说绰绰有余.
3. **应用层设计:**
    - 我们使用 **Go** 来编写应用服务, Go 的高并发模型 (Goroutine) 非常适合这种 I/O 密集型的场景.
    - 我们对单个服务实例进行了压测, 发现单核 CPU, 2G 内存的容器实例可以稳定处理约 500 QPS 的抢购请求.
    - 因此, 为了达到 1500 QPS 的目标并保证高可用, 我们部署了 **4 个** 这样的服务实例 (`1500 / 500 = 3`, 额外一个用于冗余和流量波动), 前面用负载均衡器进行分发.
4. **数据库解耦:** 最关键的是, 这 1500 QPS 的写请求, 并没有直接写入数据库. 而是转化为了 1500条/秒的消息发送到了 **Kafka**. Kafka 的吞吐能力非常高, 完全能承受这个写入量. 而后端的数据库消费者服务则可以按照比如 200 QPS 的速度去平稳消费, 数据库压力非常小.
所以, 这个设计是通过 **Redis 扛住核心压力 + Go 服务水平扩展 + Kafka 削峰填谷** 来实现的.”
---
### 用什么工具进行压测 / 压测的这些请求是一样的还是按照一定规则变化
“我们主要使用 **k6** 这款开源的性能压测工具. 选择它是因为它本身是 Go 编写的, 性能很高, 并且可以用 JavaScript 编写灵活的压测脚本.
压测的请求 **不是完全一样的, 而是尽可能模拟真实的用户行为**:
1. **混合场景 (Mixed Scenarios):** 我们的压测脚本会定义多个场景. 比如, 90% 的虚拟用户在执行‘只读’操作 (刷新商品详情页), 10% 的虚拟用户在执行‘抢购’操作 (调用抢购接口). 这更符合真实的用户流量模型.
2. **动态数据:** 每个虚拟用户发起的请求都带有 **唯一的 `userId` 和 `authToken`**. 这些数据我们会预先生成并存储在一个 CSV 文件中, k6 脚本可以在运行时读取这些文件, 确保每个请求都是来自一个'不同'的用户.
3. **负载模式 (Load Pattern):** 我们不采用恒定的并发数. 而是使用‘阶梯式加压 (Ramping VUs)’模式. 比如, 在 1 分钟内, 并发用户数从 0 线性增加到 2000; 然后维持 2000 并发运行 5 分钟; 最后在 1 分钟内再降回 0. 这样做的好处是, 我们可以清晰地看到系统在哪个压力水平下开始出现性能拐点.”
---
### 了解限流吗, 项目里有实现吗
“了解. 限流是保护系统不被冲垮的关键手段, 在我们的项目中有两层实现:
1. **API 网关层限流:** 我们在项目的入口, 也就是 API 网关 (我们使用的是 Kong), 配置了基于 **令牌桶 (Token Bucket)** 算法的全局限流. 比如, 我们设置整个抢购接口的速率为 2000 rps (每秒请求数). 这意味着每秒钟系统会生成 2000 个令牌, 每个请求消耗一个, 没有令牌的请求会被直接拒绝 (返回 429 Too Many Requests). 这一层主要用于拦截掉最顶峰的无效流量.
2. **应用服务层限流:** 我们还对一些更具体的用户行为做了限流. 例如, 为了防止单个用户恶意高频点击, 我们实现了一个基于用户 ID 的限流器. 它的原理是 **滑动窗口计数器**, 用 Redis 的 `ZSET` 或 `INCR`+`EXPIRE` 来实现. 比如, 限制单个用户在 1 秒内只能请求 1 次. 如果用户请求过于频繁, 应用服务会直接拒绝, 不会走到后续的业务逻辑.”
---
### Go 中什么数据结构是值拷贝, 引用拷贝
“在 Go 中, 有一个重要的概念需要先明确: **Go 语言中所有的函数传参都是值拷贝 (pass-by-value)**. 所谓的‘引用拷贝’实际上是拷贝了一个‘引用类型’的值, 这个值本身就像一个指针或描述符.
- **值拷贝 (Value Types):** 当这些类型的变量被赋值或传递给函数时, 会完整地复制整个数据结构. 修改副本不会影响原始值.
    - 主要包括: **`int`, `float`, `string`, `bool`** 等基本类型, 以及 **`struct`** 和 **`array`**. 对一个 `struct` 进行赋值, 是深拷贝其所有字段.
- **引用拷贝 (Reference Types):** 当这些类型的变量被赋值或传递时, 拷贝的是它们的‘描述符’或‘头信息’ (header). 这个描述符很小, 并且内部包含一个指向底层数据结构的指针. 因此, 通过副本修改底层数据, 会影响到原始变量.
    - 主要包括: **`slice`, `map`, `channel`**.
    - 例如, `slice` 的头信息包含一个指向底层数组的指针, 以及 `len` 和 `cap` 字段. 拷贝 `slice` 时, 只是拷贝了这个头信息, 两个 `slice` 变量会指向同一个底层数组.”
---
### 讲一下 slice 和 数组 / 为什么 Go 要引入 slice 和数组
- **数组 (Array):**
    - 是具有 **固定长度** 且包含相同类型元素的序列.
    - 长度是其 **类型的一部分**. `[4]int` 和 `[5]int` 是两种完全不同的类型.
    - 是 **值类型**.
- **切片 (Slice):**
    - 是 **动态长度** 的, 它灵活地表示数组的一部分或全部.
    - 它是一个轻量级的 **引用类型** 数据结构, 包含三个字段: 指向底层数组的指针 (Pointer), 长度 (Length), 和容量 (Capacity).
为什么 Go 同时需要这两种?
这是 Go 在 性能控制 和 编程便利性 之间做出的一种权衡和设计.
1. **数组提供了底层和可预测性:** 数组是构成切片的基础. 它代表了一块连续的, 大小已知的内存. 在一些需要精确控制内存布局, 或者不希望有动态扩容开销的性能敏感场景 (比如底层网络编程, 嵌入式开发), 数组是不可或缺的. 它给了程序员最原始的控制力.
2. **切片提供了灵活性和便利性:** 在绝大多数应用层开发中, 我们处理的数据集合大小是动态变化的. 如果只有数组, 每次增加元素都需要手动创建一个更大的数组并复制所有旧元素, 这非常繁琐且低效. **切片** 就是 Go 语言提供的官方解决方案, 它封装了这些复杂的动态数组管理逻辑 (包括自动扩容), 提供了非常方便和高效的接口 (`append`, `copy` 等). 它是 Go 语言中最常用, 最具代表性的数据结构.
所以, **数组是‘骨架’, 提供了内存层面的确定性; 切片是‘血肉’, 提供了编程层面的灵活性.**
---
### goroutine 中只能用 channel 的, 什么联系 / goroutine 中怎么用锁的
“这个说法不完全准确. Go 的并发哲学确实是 **推荐使用 channel 来进行通信以共享内存**, 而不是通过共享内存来通信. 但这是一种设计哲学上的推荐, 而非语言上的强制限制. Go 同样提供了完善的传统锁机制.
Goroutine 与 Channel 的联系:
Channel 是 Go 语言内置的, 用于在 Goroutine 之间传递数据和进行同步的管道. 它们是 Go 并发模型的核心.
- **数据安全:** 往一个 channel 发送数据, 或从一个 channel 接收数据, 本身是原子操作. 这使得在多个 goroutine 之间传递数据天然就是线程安全的.
- **同步:** Channel 默认是阻塞的. 发送操作会阻塞直到有接收者准备好, 接收操作会阻塞直到有发送者发送数据. 这种阻塞特性使得 goroutine 之间可以无需显式加锁就能实现同步.
Goroutine 中怎么用锁:
Go 在 sync 包中提供了传统的锁机制, 最常用的是 sync.Mutex (互斥锁).
- **使用场景:** 当多个 goroutine 需要共享访问某个数据结构 (比如一个全局计数器, 或一个缓存 map) 时, 使用互斥锁来保护这个共享资源是一个非常直接和有效的方法.
- **示例:**
    Go
    ```
    var (
        mu      sync.Mutex
        counter int
    )
    func increment() {
        mu.Lock()         // 加锁
        defer mu.Unlock() // 确保函数退出时解锁
        counter++
    }
    ```
    在需要访问 `counter` 的 goroutine 中, 都会调用 `increment` 函数. `mu.Lock()` 会保证同一时刻只有一个 goroutine 能进入临界区 (修改 `counter` 的代码), 从而避免了数据竞争.
**总结:** Channel 是 Go 的一等公民, 用于 **goroutine 之间的通信和同步**; 锁是重要的补充, 用于 **保护共享内存区域**. 两者都是 Go 并发编程的工具箱里的重要工具, 应根据具体场景选择最合适的那个.
---
### 讲一下 Go 的泛型 / 讲一下 Go 的接口
#### Go 的泛型
泛型是 Go 1.18 版本引入的重大特性. 它允许我们编写不依赖于特定具体类型的函数和数据结构.
- **作用:** 主要为了 **减少代码重复**. 在没有泛型之前, 如果我们想写一个函数来处理 `int` 类型的切片和 `float64` 类型的切片, 我们需要写两个几乎一模一样的函数, 或者使用 `interface{}` (即 `any`) 配合类型断言, 但后者不保证类型安全且有性能开销.
- **语法:** 使用方括号 `[]` 来声明类型参数.
    Go
    ```
    // T 是类型参数, any 是它的约束, 表示可以是任何类型
    func PrintSlice[T any](s []T) {
        for _, v := range s {
            fmt.Println(v)
        }
    }
    ```
- **约束 (Constraint):** 我们可以通过接口来定义类型参数必须满足的约束. 比如, 定义一个只接受 `int` 或 `float64` 的泛型函数.
#### Go 的接口
接口 (Interface) 是 Go 语言实现多态的核心. 它是一种抽象类型, 定义了一组方法的集合 (即行为).
- **核心特点: 非侵入式/隐式实现.** 这是 Go 接口与其他语言最大的不同. 一个类型只要实现了接口中定义的所有方法, 那么它就自动地, 隐式地实现了这个接口. 无需像 Java 那样使用 `implements` 关键字显式声明.
- **作用:**
    1. **实现多态:** 我们可以编写一个接受接口类型参数的函数, 那么任何实现了该接口的类型的实例都可以传递给这个函数.
    2. **代码解耦:** 通过面向接口编程, 我们可以将具体的实现与调用方解耦, 提高代码的灵活性和可扩展性.
- **空接口 `interface{}` (或 `any`):** 这是一个特殊的接口, 它不包含任何方法. 因此, Go 中的任何类型都默认实现了空接口. 它常用于处理未知类型的数据, 但在泛型出现后, 很多场景下泛型是更类型安全的选择.
---
### 讲一下了解的设计模式, 讲了策略模式
“我了解多种设计模式, 如单例模式, 工厂模式, 观察者模式等. 如果要详细讲一个, 我觉得 **策略模式 (Strategy Pattern)** 在 Go 中能被非常优雅地实现.
**策略模式的定义** 是: 定义一系列算法, 将每一个算法封装起来, 并使它们可以相互替换. 该模式使得算法可独立于使用它的客户而变化.
在 Go 中的应用:
这个模式与 Go 的 接口 简直是天作之合.
1. **定义策略接口:** 首先, 我们定义一个策略接口, 它包含一个算法方法.
    Go
    ```
    type PaymentStrategy interface {
        Pay(amount float64) string
    }
    ```
2. **实现具体策略:** 然后, 我们创建多个实现了该接口的具体策略.
    Go
    ```
    type AliPay struct{}
    func (a *AliPay) Pay(amount float64) string {
        return fmt.Sprintf("Paid %.2f using AliPay", amount)
    }
    type WechatPay struct{}
    func (w *WechatPay) Pay(amount float64) string {
        return fmt.Sprintf("Paid %.2f using WeChat Pay", amount)
    }
    ```
3. **创建上下文 (Context):** 最后, 创建一个上下文, 它持有一个策略接口类型的成员, 并有一个方法来执行策略.
    Go
    ```
    type PaymentContext struct {
        Strategy PaymentStrategy
    }
    func (c *PaymentContext) ExecutePayment(amount float64) {
        result := c.Strategy.Pay(amount)
        fmt.Println(result)
    }
    ```
**好处:** 客户端代码可以通过给 `PaymentContext` 设置不同的策略实例 (如 `&AliPay{}` 或 `&WechatPay{}`), 在 **运行时** 动态地改变支付行为, 而 `PaymentContext` 自身完全不需要知道具体的支付逻辑是什么. 这完美地实现了算法和客户端的解耦.”
### MySQL 和 Redis 的区别, 它们的技术选型, 应用场景, 讲讲理解
“MySQL 和 Redis 是现代后端架构中两种不同定位, 但通常配合使用的数据库.
核心区别:

| 特性   | MySQL                  | Redis                         |
| :--- | :--------------------- | :---------------------------- |
| 类型   | 关系型数据库 (RDBMS)         | NoSQL 键值 (Key-Value) 数据库      |
| 存储介质 | 磁盘 (Disk-based)        | 内存 (In-memory)                |
| 性能   | 相对较慢, 受磁盘I/O限制         | 极快, 操作在内存中完成                  |
| 数据模型 | 结构化的表, 行, 列 (Schema)   | 灵活的数据结构 (String, List, Hash等) |
| 持久化  | 强持久化, ACID 事务          | 可选持久化 (RDB, AOF)              |
| 查询能力 | 强大的 SQL, 支持复杂 JOIN 和聚合 | 简单的 Key 查询或基于数据结构的查询          |
技术选型与应用场景 (我的理解):
它们不是竞争关系, 而是 黄金搭档, 在架构中扮演不同的角色.
- **MySQL 的角色: 系统的数据基石 (System of Record)**
    - **选型理由:** 当数据要求 **强一致性, 持久化, 并且需要复杂查询和事务支持** 时, 必须选择 MySQL.
    - **应用场景:**
        - 用户信息, 商品信息, 订单数据等核心业务数据.
        - 需要保证事务ACID特性的金融数据.
        - 需要进行多表关联查询和数据分析的场景.
- **Redis 的角色: 系统的加速器和功能扩展器 (Accelerator & Extension)**
    - **选型理由:** 当业务场景要求 **极高的读写性能, 或者需要利用其特殊的数据结构** 时, 选择 Redis.
    - **应用场景:**
        - **缓存:** 作为 MySQL 的缓存层, 缓存热点数据 (如用户信息), 减少对数据库的直接访问, 这是最常见的用法.
        - **分布式会话 (Session):** 存储用户登录状态.
        - **计数器/限流器:** 利用其原子性的 `INCR` 命令.
        - **排行榜:** 利用 `ZSET` (有序集合).
        - **简单的消息队列:** 利用 `LIST` 的 `LPUSH`/`RPOP` 操作.
        - **分布式锁:** 利用 `SETNX` 实现.
**总结:** 我的理解是, 用 MySQL 来 **‘存储’** 那些必须可靠存放的核心数据, 用 Redis 来 **‘加速’** 那些需要被频繁和快速访问的数据和业务逻辑.”
---
### 讲解对 MySQL 索引的理解 / 有没有用过 elasticsearch
“我对 MySQL 索引的理解是, 它是一种为了 **加速数据检索** 而创建的, 需要额外存储空间的数据结构. 其核心目的就是用 **空间换时间**.
- **底层数据结构:** 在 InnoDB 存储引擎中, 索引主要是通过 **B+树** 实现的. B+树的特点 (多路平衡, 数据只在叶子节点, 叶子节点有序且有指针相连) 使其非常适合磁盘存储, 能够大大减少查询时的磁盘 I/O 次数.
- **索引类型:**
    - **聚簇索引 (Clustered Index):** 通常是主键. B+树的叶子节点直接存储了 **完整的数据行**. 一张表只有一个聚簇索引.
    - **二级索引 (Secondary Index):** 普通索引. B+树的叶子节点存储的是 **索引列的值和对应行的主键**. 当通过二级索引查询非索引列的数据时, 需要先找到主键, 再通过主键去聚簇索引中查找完整数据, 这个过程叫 **回表**.
- **索引使用的关键原则:**
    - **最左前缀原则:** 对于联合索引 `(a, b, c)`, 查询条件必须从最左边的列开始, 才能有效利用索引. `WHERE a=1` 和 `WHERE a=1 AND b=2` 都可以, 但 `WHERE b=2` 则不行.
    - **避免在索引列上进行计算或使用函数**, 这会导致索引失效.
关于 Elasticsearch:
“我没有在生产项目中深入使用过 Elasticsearch, 但对它有基本的了解. 我知道它是一个基于 Lucene 库的 分布式搜索和分析引擎.
- **核心优势:** 它的核心能力在于 **全文检索 (Full-text Search)**. 当我们需要实现复杂的文本搜索功能, 比如像电商网站那样的商品搜索 (支持分词, 模糊匹配, 排序, 过滤) 时, MySQL 的 `LIKE '%text%'` 是完全无法满足性能和功能需求的, 这时就应该使用 Elasticsearch.
- **其他用途:** 它也常被用于日志聚合和分析 (ELK Stack 中的 E), 以及实时数据分析等场景. 它和 MySQL 也是典型的组合使用关系, 通过某种同步机制 (如 Canal) 将 MySQL 中的数据同步到 ES 中, 以提供强大的搜索能力.”
---
### 共享本地ide手撕反转链表
[[反转链表]]
### http 和 tcp 的区别 / 开始比较随便的问题
- HTTP 和 TCP 的区别:
    “它们是计算机网络模型中不同层次的协议.
    - **TCP (传输控制协议):** 是 **传输层 (Layer 4)** 的协议. 它的主要职责是提供一个 **可靠的, 面向连接的, 有序的** 数据传输通道. 它负责将大的数据块分割成小的数据包, 进行流量控制, 拥塞控制, 保证数据不丢失, 不重复, 并且按顺序到达. 它就像一个‘可靠的快递公司’, 只负责把包裹完好无损地按顺序送到, 但不关心包裹里是什么.
    - **HTTP (超文本传输协议):** 是 **应用层 (Layer 7)** 的协议. 它 **构建在 TCP 之上**. 它的主要职责是定义客户端和服务器之间通信的 **内容格式和规则**. 比如, 它定义了 `GET`, `POST` 等请求方法, `Content-Type` 等头部信息, 以及 `200 OK`, `404 Not Found` 等状态码. 它就像是快递包裹上填写的‘寄件单’, 规定了包裹的内容是什么, 以及收件人该如何处理这个包裹.”
- **有没有用过腾讯云或者阿里云:** “用过. 在之前的项目中, 我们的服务主要部署在 **阿里云** 上. 我对它的一些核心产品比较熟悉, 比如 **ECS** (云服务器), **RDS** (关系型数据库服务), **ACK** (容器服务 for Kubernetes), 以及 **OSS** (对象存储) 等.”
- **有没有用过 k8s / docker:**
    - **Docker:** “用过, Docker 是我们整个开发和部署流程的基石. 我们使用 Docker 将 Go 应用和其所有依赖打包成一个标准的 **容器镜像**, 这保证了从开发, 测试到生产环境的一致性, 解决了‘在我电脑上能跑’的问题.”
    - **Kubernetes (k8s):** “是的, 我们的生产环境就是一套 **Kubernetes 集群**. Docker 帮我们打包单个应用, 而 Kubernetes 负责 **编排和管理** 成百上千个这样的容器. 我熟悉 Kubernetes 的一些核心概念, 比如 `Pod`, `Deployment`, `Service` 等. 我知道如何编写 `Deployment` 的 YAML 文件来部署和更新我们的服务, 以及如何通过 `Service` 来暴露端口和实现服务发现.”
- **项目怎么部署服务的, docker 部署有什么优势:**
    - “我们的项目采用 **基于 Kubernetes 和 Docker 的 CI/CD 流程** 进行自动化部署.
        1. 开发者将代码推送到 Git 仓库.
        2. 触发 Jenkins 或 GitLab CI 管道.
        3. CI/CD 服务器拉取代码, 运行单元测试, 然后执行 `docker build` 构建一个新的镜像.
        4. 将新镜像推送到阿里云的容器镜像服务 (ACR) 中.
        5. 最后, CI/CD 工具通过 `kubectl apply` 命令, 更新 Kubernetes 中对应服务的 `Deployment` 文件, 将镜像版本指向最新的版本. Kubernetes 会自动地以 **滚动更新 (Rolling Update)** 的方式, 逐个替换旧的 Pod, 从而实现平滑的应用升级.
    - **Docker 部署的优势非常明显:**
        1. **环境一致性:** 打包了所有依赖, 避免了环境差异导致的问题.
        2. **快速部署与弹性伸缩:** 容器的启动速度远快于虚拟机, 结合 K8s 可以实现秒级的扩容和缩容.
        3. **资源隔离与利用率:** Docker 提供了良好的资源隔离, 可以在同一台物理机上运行更多的应用, 提高资源利用率.
        4. **简化运维:** 标准化的交付物 (镜像) 和标准化的编排平台 (K8s) 大大简化了运维的复杂性.”
# 二面
自我介绍
讲讲业务项目的难点亮点，以及整个抢购流程
讲完以后一直在对项目进行拷打
项目具体怎么部署的
每个服务只部署一个实例吗
怎么用rocketmq实现分布式事务的
什么是熔断降级，项目中具体熔断限流策略怎么做的，不是很满意我的限流方案
八股问的不多
分布式事务的特点
MySQL事务
go的底层知识，讲讲slice和channel的底层原理
手撕三数之和变式，给定一个数组和目标值，在数组里找三个数，要求三个数之和最接近目标值，题目保证有且只有一个满足要求的情况
最近在看什么书，学什么新知识
反问