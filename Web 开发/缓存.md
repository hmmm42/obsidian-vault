# 缓存雪崩
大量数据在 redis 中 **不存在**, 大量请求直接访问数据库
- 冷启动: 提前预热, 写入热数据 *但可能导致 大量数据同时过期*
- 大量数据**同时过期**: 
	- 设计随机过期时间
	- 服务降级: 保证资源优先级, 只提供核心数据
	- 互斥锁, 保证同一个时间只有一个请求构建缓存
	- 定时更新缓存 + 后台线程检测缓存是否有效 / 缓存失效后通知后台更新缓存
# 缓存崩溃
redis 宕机
- 服务熔断, 停止对 db 的访问, 为 redis 提供恢复时间
- 请求限流, 限制一部分请求数
- 部署高可用集群, 主从节点
# 缓存击穿
**热点数据过期**, 大量请求直接访问数据库
*情况与缓存雪崩类似*
- 互斥锁: 如果获取不到锁的线程: ==时间换空间==
	- 退避重试 or 直接返回 404 or 维护一个本地缓存
	- 如果只用 go 内置的互斥锁, 存在问题: 
		- 访问不同的 key, 要获取不同的对应的锁, 用 `map[key]sync.Mutex`
		- `map`不是并发安全, 需要用`sync.Map`, 不适合写多的场景
	- 解决: 使用分布式锁的思路, Redis 的 `setNX`, 实际场景用 `redsync`
- 逻辑过期: 类似*软删除*, 用字段来标记 key 的过期时间 ==空间换时间==
	- 如果已经过期, 获取互斥锁向 db 重建缓存
	- 无论获取锁是否成功, 都**立刻返回旧数据**
	- 存在**数据不一致**
- `singleflight`: 保证单独的 key 请求只执行一次
- 定时更新缓存
# 缓存穿透
请求数据在缓存和数据库中 **都不存在**, 直接访问数据库
原因: 业务误操作, 恶意攻击
- 提前限制非法请求
- 缓存空对象: 当一个请求发现数据在 db 和 cache 都不存在, 将 NullData 标识写入缓存
- 布隆过滤器: 预先存储所有合法的 key, 请求时先判断 key 是否存在
# 缓存数据一致性
## 更新数据库+更新缓存
并发时数据不一致
*解决: 分布式锁+过期时间* 
## 删除缓存+更新数据库
可能导致数据不一致(删除后查询到为空, 访问数据库获得旧数据)
*解决: 延迟双删 更新数据库后, 睡眠一段时间再删一次*

但是仍然有短板:
- 无法保证及时一致性, 写 db 到延时执行二次删 cache 操作期间有 **脏数据**
- 延时双删如果失败, cache 数据不一致

解决: ==本质上要避免读流程把脏数据写入 cache== 对每一笔数据启用一个 **开关**
==写缓存禁用==机制:
- 每当有**写流程到达时，先将该笔数据的“开关”关闭，然后正常执行后续流程，执行完成后再重新将“开关”打开**
- **在“开关”关闭期间**，所有到达的读流程正常执行步骤，唯独**不会在读 db 后执行写 cache 操作**
- 写流程完成写 db 操作后，**延迟一段时间**再重新开启该笔数据下的 “写缓存机制”
## 更新数据库+删除缓存
最优 **缓存的写入通常要远远快于数据库的写入**
==如果删除缓存时失败, 会出现短暂数据不一致(依靠过期时间兜底)==
*解决: 消息队列重试 / 订阅 MySQL binlog*
