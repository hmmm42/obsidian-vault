**1. 核心思想:**
一致性哈希的目标是解决在分布式缓存中, 当节点数量发生变化时, 尽量减少数据迁移量的问题. 我会通过构建一个哈希环来实现这一点.
**2. 数据结构:**
为了实现这个哈希环, 我需要两个主要的数据结构:
  * 一个 **Map (字典)**, 用来存储哈希值到真实节点名称的映射. 这样我可以通过哈希值快速找到对应的节点.
  * 一个 **有序的切片 (Sorted Slice)**, 用来存储所有虚拟节点的哈希值. 保持这个切片的有序性是关键, 因为它能让我们使用高效的二分查找来定位key.
**3. 关键特性:**
  * **虚拟节点 (Virtual Nodes):** 为了解决数据倾斜问题, 我会引入虚拟节点的概念. 每个真实节点都会对应多个虚拟节点, 这些虚拟节点会更均匀地分布在哈希环上.
  * **哈希函数:** 我会假设有一个可靠的哈希函数(比如 CRC32 或 MurmurHash), 在这里为了演示方便, 我会使用标准库里的 `crc32`.
```go
package main
import (
	"fmt"
	"hash/crc32"
	"sort"
	"strconv"
)
// HashFunc 定义了哈希函数的类型, 方便未来替换.
type HashFunc func(data []byte) uint32
// ConsistentHashMap 是一致性哈希算法的主结构.
type ConsistentHashMap struct {
	hashFunc     HashFunc       // 使用的哈希函数
	replicas     int            // 每个真实节点的虚拟节点数量
	keys         []int          // 哈希环, 存储所有虚拟节点的哈希值, 保持有序
	hashMap      map[int]string // 存储虚拟节点哈希值到真实节点名称的映射
}
// New 创建一个 ConsistentHashMap 实例.
// replicas 是虚拟节点的数量, fn 是哈希函数.
func New(replicas int, fn HashFunc) *ConsistentHashMap {
	if fn == nil {
		// 如果没有提供哈希函数, 使用默认的 CRC32.
		fn = crc32.ChecksumIEEE
	}
	return &ConsistentHashMap{
		hashFunc:     fn,
		replicas:     replicas,
		keys:         make([]int, 0),
		hashMap:      make(map[int]string),
	}
}
// Add 将一个或多个节点添加到哈希环中.
// nodeNames 是真实节点的名称列表.
func (c *ConsistentHashMap) Add(nodeNames ...string) {
	if len(nodeNames) == 0 {
		return
	}
	// 为每个真实节点创建虚拟节点
	for _, nodeName := range nodeNames {
		for i := 0; i < c.replicas; i++ {
			// 虚拟节点的名称格式: nodeName#i
			virtualNodeKey := nodeName + "#" + strconv.Itoa(i)
			// 计算虚拟节点的哈希值
			hash := int(c.hashFunc([]byte(virtualNodeKey)))
			// 将哈希值添加到环上
			c.keys = append(c.keys, hash)
			// 建立哈希值与真实节点的映射关系
			c.hashMap[hash] = nodeName
		}
	}
	// 对哈希环上的所有值进行排序, 这是二分查找的前提.
	sort.Ints(c.keys)
}
// Remove 从哈希环中移除一个节点.
// nodeName 是真实节点的名称.
func (c *ConsistentHashMap) Remove(nodeName string) {
    if nodeName == "" {
        return
    }
    // 移除该真实节点对应的所有虚拟节点
    for i := 0; i < c.replicas; i++ {
        virtualNodeKey := nodeName + "#" + strconv.Itoa(i)
        hash := int(c.hashFunc([]byte(virtualNodeKey)))
        // 1. 从哈希环(keys)中移除
        // 使用二分查找找到要删除的哈希值的位置
        idx := sort.SearchInts(c.keys, hash)
        if idx < len(c.keys) && c.keys[idx] == hash {
            //找到了, 删除它
            c.keys = append(c.keys[:idx], c.keys[idx+1:]...)
        }
        // 2. 从 hashMap 中删除映射关系
        delete(c.hashMap, hash)
    }
}
// Get 根据给定的 key, 从哈希环中查找并返回对应的真实节点名称.
func (c *ConsistentHashMap) Get(key string) string {
	if len(c.keys) == 0 {
		// 如果环上没有任何节点, 返回空字符串.
		return ""
	}
	// 计算 key 的哈希值.
	hash := int(c.hashFunc([]byte(key)))
	// 使用二分查找在哈希环上寻找第一个大于或等于 key 哈希值的虚拟节点.
	// sort.Search() 是一个非常高效的二分查找实现.
	// 它会返回满足 f(i) 为 true 的最小索引 i.
	idx := sort.Search(len(c.keys), func(i int) bool {
		return c.keys[i] >= hash
	})
	// 这里需要处理一个 "环形" 的边界情况.
	// 如果查找到的索引等于环的长度, 说明 key 的哈希值大于所有节点的哈希值,
	// 此时应该选择环上的第一个节点(0号索引), 形成一个闭环.
	if idx == len(c.keys) {
		idx = 0
	}
	// 通过哈希环上的值(c.keys[idx]), 从 map 中找到对应的真实节点名称.
	return c.hashMap[c.keys[idx]]
}
// main 函数用于演示.
func main() {
	// 创建一个实例, 每个真实节点有 10 个虚拟节点.
	chash := New(10, nil)
	// 添加3个节点.
	chash.Add("node-A", "node-B", "node-C")
	fmt.Println("Initial nodes added: A, B, C")
	// 模拟一些 key 的路由.
	testKeys := []string{"my-key-1", "another-key-2", "user-data-3", "session-id-4"}
	fmt.Println("\n--- Key distribution ---")
	for _, key := range testKeys {
		node := chash.Get(key)
		fmt.Printf("Key [%s] is routed to Node [%s]\n", key, node)
	}
	// 模拟添加一个新节点.
	fmt.Println("\n--- Adding a new node: node-D ---")
	chash.Add("node-D")
	// 再次检查 key 的路由, 观察变化.
	// 理论上, 只有一小部分 key 会被重新映射到 node-D.
	fmt.Println("\n--- Key distribution after adding node-D ---")
	for _, key := range testKeys {
		node := chash.Get(key)
		fmt.Printf("Key [%s] is now routed to Node [%s]\n", key, node)
	}
    // 模拟移除一个节点.
    fmt.Println("\n--- Removing a node: node-B ---")
    chash.Remove("node-B")
    // 再次检查 key 的路由, 观察变化.
    // 理论上, 属于 node-B 的 key 会被均匀地重新映射到 A, C, D.
    fmt.Println("\n--- Key distribution after removing node-B ---")
	for _, key := range testKeys {
		node := chash.Get(key)
		fmt.Printf("Key [%s] is now routed to Node [%s]\n", key, node)
	}
}
```
### 讲解总结
“面试官您好, 以上就是我实现的一致性哈希算法.
  * **结构清晰**: 通过 `ConsistentHashMap` 结构体封装了所有必要的数据和方法.
  * **功能完备**: 实现了核心的 `Add`, `Get` 和 `Remove` 方法.
  * **性能高效**: `Get` 操作利用了有序切片和二分查找, 其时间复杂度是 `O(log M)`, 其中 `M` 是虚拟节点的总数. `Add` 和 `Remove` 操作因为需要维持切片有序, 其复杂度是 `O(N*logM)`, `N`是新增/删除节点的虚拟节点数, `M`是总虚拟节点数.
  * **设计考虑**: 引入了虚拟节点来保证数据分布的均衡性, 并将哈希函数作为参数, 增加了代码的灵活性.
这个实现兼顾了正确性, 性能和可扩展性, 能够很好地满足分布式缓存场景下的节点动态变化需求.”