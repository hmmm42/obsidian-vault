# 性质
- 独占性：对于同一把锁，在同一时刻只能被一个取锁方占有，这是锁最基础的一项特征
- 健壮性：即不能产生死锁（dead lock）. 假如某个占有锁的使用方因为宕机而无法主动执行解锁动作，锁也应该能够被正常传承下去，被其他使用方所延续使用
- 对称性：加锁和解锁的使用方必须为同一身份. 不允许非法释放他人持有的分布式锁
- 高可用：当提供分布式锁服务的基础组件中存在少量节点发生故障时，应该不能影响到分布式锁服务的稳定性
==分布式读写锁不可行: 复杂性极高, 死锁, 性能没优势(读锁也是锁)==
# 类型
- 主动轮询型：该模型类似于单机锁中的主动轮询 + cas 乐观锁模型，取锁方会持续对分布式锁发出尝试获取动作，如果锁已被占用则会不断发起重试，直到取锁成功为止  
	- Redis `SETNX`
	- MySQL 唯一键约束
- watch 回调型：在取锁方发现锁已被他人占用时，会创建 ==watcher 监视器订阅锁的释放事件==，随后不再发起主动取锁的尝试；当锁被释放后，取锁方能通过之前创建的 watcher 感知到这一变化，然后再重新发起取锁的尝试动作
	- etcd 
	- Zookeeper
# Redis分布式锁
## 思路
Redis 实现分布式锁, 思路是 **主动轮询**
- 针对于同一把分布式锁，使用同一条数据进行标识（以 redis 为例，则为同一个 key 对应的 kv 数据记录）
- 假如在存储介质成功插入了该条数据（要求之前该 key 对应的数据不存在），则被认定为加锁成功
- 把从存储介质中删除该条数据这一行为理解为释放锁操作
- 倘若在插入该条数据时，发现数据已经存在（锁已被他人持有），则持续轮询，直到数据被他人删除（他人释放锁），并由自身完成数据插入动作为止（取锁成功）
- 由于是并发场景，需要保证【（1）检查数据是否已被插入（2）数据不存在则插入数据】这两个步骤之间是原子化不可拆分的（在 redis 中是 set only if not exist —— `SETNX`操作）
## 加锁
方式分为`tryLock`和`Lock`, 根据是否处于阻塞模式来区分
```go
const RedisLockKeyPrefix = "REDIS_LOCK_PREFIX_"

// Lock 加锁.
func (r *RedisLock) Lock(ctx context.Context) (err error) {
	defer func() {
		if err != nil {
			return
		}
		// 加锁成功的情况下，会启动看门狗
		// 关于该锁本身是不可重入的，所以不会出现同一把锁下看门狗重复启动的情况
		r.watchDog(ctx)
	}()
    
	// 不管是不是阻塞模式，都要先获取一次锁
	err = r.tryLock(ctx)
	if err == nil {
		return nil
	}
	
	// 非阻塞模式加锁失败直接返回错误
	if !r.isBlock {
		return err
	}
	
	// 判断错误是否可以允许重试，不可允许的类型则直接返回错误
	if !IsRetryableErr(err) {
		return err
	}
	
	// 基于阻塞模式持续轮询取锁
	return r.blockingLock(ctx)
}

func (r *RedisLock) tryLock(ctx context.Context) error {
	// 首先查询锁是否属于自己
	reply, err := r.client.SetNEX(ctx, r.getLockKey(), r.token, r.expireSeconds)
	if err != nil {
		return err
	}
	if reply != 1 {
		return fmt.Errorf("reply: %d, err: %w", reply, ErrLockAcquiredByOthers)
	}
	return nil
}

func (r *RedisLock) getLockKey() string {
	return RedisLockKeyPrefix + r.key
}
```

```go
func (r *RedisLock) blockingLock(ctx context.Context) error {
	// 阻塞模式等锁时间上限
	timeoutCh := time.After(time.Duration(r.blockWaitingSeconds) * time.Second)
	// 轮询 ticker，每隔 50 ms 尝试取锁一次
	ticker := time.NewTicker(time.Duration(50) * time.Millisecond)
	defer ticker.Stop()
	
	for range ticker.C {
		select {
		// ctx 终止了
		case <-ctx.Done():
			return fmt.Errorf("lock failed, ctx timeout, err: %w", ctx.Err())
			// 阻塞等锁达到上限时间
		case <-timeoutCh:
			return fmt.Errorf("block waiting time out, err: %w", ErrLockAcquiredByOthers)
		// 放行
		default:
		}
		
		// 尝试取锁
		err := r.tryLock(ctx)
		if err == nil {
			// 加锁成功，返回结果
			return nil
		}
		
		// 不可重试类型的错误，直接返回
		if !IsRetryableErr(err) {
			return err
		}
	}
	
	return nil
}
```
## 解锁
基于 lua 脚本原子化
1. `get`操作, 校验当前操作者是否拥有锁的所有权
2. 倘若是，执行`del`删除锁数据, 释放锁
```go
// Unlock 解锁. 基于 lua 脚本实现操作原子性.
func (r *RedisLock) Unlock(ctx context.Context) (err error) {
	defer func() {
		if err != nil {
			return
		}
		// 停止看门狗
		if r.stopDog != nil {
			r.stopDog()
		}
	}()

	keysAndArgs := []interface{}{r.getLockKey(), r.token}
	reply, _err := r.client.Eval(ctx, LuaCheckAndDeleteDistributionLock, 1, keysAndArgs)
	if _err != nil {
		err = _err
		return
	}

	if ret, _ := reply.(int64); ret != 1 {
		err = errors.New("can not unlock without ownership of lock")
	}

	return nil
}

// LuaCheckAndDeleteDistributionLock 判断是否拥有分布式锁的归属权，是则删除
const LuaCheckAndDeleteDistributionLock = `
  local lockerKey = KEYS[1]
  local targetToken = ARGV[1]
  local getToken = redis.call('get',lockerKey)
  if (not getToken or getToken ~= targetToken) then
    return 0
  else
    return redis.call('del',lockerKey)
  end
`
```
## 延期锁
基于 lua 脚本
1. `get`操作获取 val，查看是否和当前使用方身份一致
2. 如果一致，执行`expire`更新过期时间
```go
// 更新锁的过期时间，基于 lua 脚本实现操作原子性
func (r *RedisLock) DelayExpire(ctx context.Context, expireSeconds int64) error {
  keysAndArgs := []interface{}{r.getLockKey(), r.token, expireSeconds}
  reply, err := r.client.Eval(ctx, LuaCheckAndExpireDistributionLock, 1, keysAndArgs)
  if err != nil {
      return err
  }
  if ret, _ := reply.(int64); ret != 1 {
      return errors.New("can not expire lock without ownership of lock")
  }
  return nil
}
const LuaCheckAndExpireDistributionLock = `
  local lockerKey = KEYS[1]
  local targetToken = ARGV[1]
  local duration = ARGV[2]
  local getToken = redis.call('get',lockerKey)
  if (not getToken or getToken ~= targetToken) then
    return 0
  else
    return redis.call('expire',lockerKey,duration)
  end
`
```
## 过期时间问题
假如遇到长时间gc, 如何保证任期内锁不被释放
### lua脚本检验
取锁时检查当前锁是否是自己持有的, 将value设成与取锁放有关的
### 看门狗机制
机制类似etcd的`lease`，在加锁成功后，异步启动看门狗(定时器)，定时更新锁的过期时间
*保证同一时刻只会有一只看门狗*
释放锁时，停止看门狗 
```go
// 启动看门狗
func (r *RedisLock) watchDog(ctx context.Context) {
	// 1. 非看门狗模式，不处理
	if !r.watchDogMode {
		return
	}
	
	
	// 2. 确保之前启动的看门狗已经正常回收
	for !atomic.CompareAndSwapInt32(&r.runningDog, 0, 1) {
	}
	

	// 3. 启动看门狗
	ctx, r.stopDog = context.WithCancel(ctx)
	go func() {
		defer func() {
			atomic.StoreInt32(&r.runningDog, 0)
		}()
		r.runWatchDog(ctx)
	}()
}

func (r *RedisLock) runWatchDog(ctx context.Context) {
	ticker := time.NewTicker(WatchDogWorkStepSeconds * time.Second)
	defer ticker.Stop()
	
	
	for range ticker.C {
		select {
		case <-ctx.Done():
			return
		default:
		}
		
		
		// 看门狗负责在用户未显式解锁时，持续为分布式锁进行续期
		// 通过 lua 脚本，延期之前会确保保证锁仍然属于自己
		_ = r.DelayExpire(ctx, WatchDogWorkStepSeconds)
	}
}

```
## 一锁多主问题
### 红锁
==解决数据弱一致性==: 一锁多主 假如加锁后, 主节点没来得及同步就宕机了, 新选举的主节点没有锁
基于多数派原则, 需要对多个节点进行加锁, 半数以上成功才算加锁成功
如果失败, 对已加锁的节点全部解锁 
[[分布式锁 Redlock 的争议与思辨]]
### redsync
golang的红锁实现
[go-redsync/redsync: Distributed mutual exclusion lock using Redis for Go](https://github.com/go-redsync/redsync)redsync分布式锁原理：
- 如何**解决可重试**问题：利用信号量和PubSub功能实现等待、唤醒，获取锁失败的重试机制。
- 如何**解决超时续约**问题：利用watchDog，每隔一段时间（releaseTime / 3），重置超时时间。
- 如何**解决主从一致性**问题：利用redsync的multiLock，多个独立的Redis节点，必须在所有节点都获取重入锁，才算获取锁成功。其缺陷：运维成本高、实现复杂。
# etcd分布式锁
## lease租约机制
为避免死锁问题的产生，etcd 中提供了租约 lease 机制. 租约，顾名思义，是一份具有时效性的协议，一旦达到租约上规定的截止时间，租约就会失去效力. 同时，etcd 中还提供了续约机制（keepAlive），用户可以通过续约操作来延迟租约的过期时间.

那么，我们如何来利用租约 lease 机制解决分布式锁中可能存在的死锁问题呢？实现思路如下：
- 用户可以先申请一份租约，设定好租约的截止时间
- 异步启动一个续约协程，负责在业务逻辑处理完成前，按照一定的时间节奏持续进行续约操作
- 在执行取锁动作，将对应于锁的 kv 数据和租约进行关联绑定，使得锁数据和租约拥有相同的过期时间属性
在这样的设定之下，倘若分布式锁的持有者出现异常状况导致无法正常解锁，则可以通过租约的过期机制完成对分布式锁的释放，死锁问题因此得以规避. 此外，锁的使用方可以将租约的初始过期时间设定为一个偏小的值，并通过续约机制来对租约的生效周期进行动态延长. 可以看到，此处 etcd 中的租约及续约机制，实现了与 redisson 中 watch dog 机制类似的效果.
## 惊群效应
在 watch 回调型分布式锁的实现过程中，可能也会存在类似于惊群效应的问题. 这里指的是：倘若一把分布式锁的竞争比较激烈，那么锁的释放事件可能同时被多个的取锁方所监听，一旦锁真的被释放了，所有的取锁方都会一拥而上尝试取锁，然而我们知道，一个轮次中真正能够取锁成功的只会有一名角色，因此这个过程中会存在大量无意义的性能损耗，且释放锁时刻瞬间激增的请求流量也可能会对系统稳定性产生负面效应.

为规避惊群效应，etcd 中提供了前缀 prefix 机制以及版本 revision 机制，和 zookeeper 的临时顺序节点功能有些类似：
- 对于同一把分布式锁，锁记录数据的 key 拥有共同的前缀 prefix，作为锁的标识
- 每个取锁方取锁时，会以锁前缀 prefix 拼接上自身的身份标识（租约 id），生成完整的 lock key. 因此各取锁方完整的 lock key 都是互不相同的（只是有着相同的前缀），理论上所有取锁方都能成功把锁记录数据插入到 etcd 中
- 每个取锁方插入锁记录数据时，会获得自身 lock key 处在锁前缀 prefix 范围下唯一且递增的版本号 revision
- 取锁方插入加锁记录数据不意味着加锁成功，而是需要在插入数据后查询一次锁前缀 prefix 下的记录列表，判定自身 lock key 对应的 revision 是不是其中最小的，如果是的话，才表示加锁成功
- 如果锁被他人占用，取锁方会 watch 监听 revision 小于自己但最接近自己的那个 lock key 的删除事件.
这样所有的取锁方就会在 revision 机制的协调下，根据取锁序号（revision）的先后顺序排成一条队列，每当锁被释放，只会惊动到下一顺位的取锁方，惊群问题得以避免.