# 缓存雪崩
**大量数据**在 redis 中 **不存在**, 大量请求直接访问数据库 ==不是某个热点Key==
- 冷启动: 提前预热, 写入热数据 *但可能导致 大量数据同时过期*
- 大量数据**同时过期**: 
	- 设计随机过期时间
	- 服务降级: 保证资源优先级, 只提供核心数据
	- 互斥锁, 保证同一个时间只有一个请求构建缓存
	- 定时更新缓存 + 后台线程检测缓存是否有效 / 缓存失效后通知后台更新缓存
# 缓存崩溃
redis 宕机
- 服务熔断, 停止对 db 的访问, 为 redis 提供恢复时间
- 请求限流, 限制一部分请求数
- 部署高可用集群, 主从节点
# 缓存击穿
**热点数据过期**, 大量请求直接访问数据库
*情况与缓存雪崩类似*
- 互斥锁: 如果获取不到锁的线程: ==时间换空间==
	- 退避重试 or 直接返回 404 or 维护一个本地缓存
	- 如果只用 go 内置的互斥锁, 存在问题: 
		- 访问不同的 key, 要获取不同的对应的锁, 用 `map[key]sync.Mutex`
		- `map`不是并发安全, 需要用`sync.Map`, 不适合写多的场景
	- 解决: 使用分布式锁的思路, Redis 的 `setNX`, 实际场景用 `redsync`
- 逻辑过期: 类似*软删除*, 用字段来标记 key 的过期时间 ==空间换时间==
	- 如果已经过期, 获取互斥锁向 db 重建缓存
	- 无论获取锁是否成功, 都**立刻返回旧数据**
	- 存在**数据不一致**
- `singleflight`: 保证单独的 key 请求只执行一次
- 定时更新缓存
# 缓存穿透
请求数据在缓存和数据库中 **都不存在**, 直接访问数据库
原因: 业务误操作, 恶意攻击
- 提前限制非法请求
- 缓存空对象: 当一个请求发现数据在 db 和 cache 都不存在, 将 NullData 标识写入缓存
- 布隆过滤器: 预先存储所有合法的 key, 请求时先判断 key 是否存在
# 缓存数据一致性
## Read-Through / Write-Through (读穿透 / 写穿透)
这个方案将缓存和数据库的操作**封装在缓存层内部**, 应用层只与缓存交互, 对应用层来说是透明的.
- **读操作 (Read-Through)**: 应用向缓存请求数据. 如果缓存没有, 则由**缓存服务自己**负责从数据库加载数据并返回给应用.
- **写操作 (Write-Through)**: 应用向缓存写入数据. 由**缓存服务自己**负责先将数据写入数据库, 成功后再写入缓存.
- **优缺点**:
    - **优点**: 应用层逻辑简单, 将一致性逻辑下沉到了缓存服务层.
    - **缺点**: 实现相对复杂, 通常需要一个支持这种模式的缓存中间件. 并且, 每次写操作都必须等待数据库写入成功, 会增加写的延迟.
- **在Pulse项目中的思考**:
    > "我评估过这个方案, 但认为它不太适合我们的场景. 因为它增加了写的延迟, 而我们的很多写操作(如更新商铺信息)对实时性要求不高. 另外, 自建一个通用的缓存服务层成本较高, 而Cache-Aside模式已经能很好地满足我们的需求."
## Write-Back (Write-Behind Caching, 写回模式)
==相比于写穿, 区别在于异步写db==
这个方案优先保证**写的性能**.
- **写操作**: 应用只管将数据写入Redis缓存, 然后立即返回成功. 缓存服务会**异步地、批量地**将缓存中的“脏”数据刷回数据库.
- **读操作**: 与Read-Through类似.
- **优缺点**:
    - **优点**: 写入速度极快, 吞吐量非常高, 并且能合并对数据库的写操作.
    - **缺点**: **数据一致性最差**. 如果Redis宕机, 还没有来得及刷回数据库的数据就会丢失. 只适用于那些对数据丢失不敏感, 但对写性能要求极高的场景(如日志记录、计数器等).
- **在Pulse项目中的思考**:
    > "这个方案显然不适用于我们的核心交易和商铺信息, 因为数据丢失是不可接受的. 但在未来, 对于一些非关键的统计数据, 比如‘探店笔记的点赞
## Cache-Aside 旁路缓存
- 读操作:
    1. 应用先从Redis读取数据.
    2. 如果缓存命中, 直接返回.
    3. 如果缓存未命中, 则从MySQL读取数据.
    4. 读取成功后, 将数据写入Redis, 并设置一个过期时间, 然后返回给客户端.
- 写操作:
### 更新数据库+更新缓存
并发时数据不一致, 两个操作不原子性, 不能确保并发线程中对redis更新的顺序
*解决: 分布式锁+过期时间* 
### 删除缓存+更新数据库
可能导致数据不一致(删除后查询到为空, 访问数据库获得旧数据)
*解决: 延迟双删 更新数据库后, 睡眠一段时间再删一次*

但是仍然有短板:
- 无法保证及时一致性, 写 db 到延时执行二次删 cache 操作期间有 **脏数据**
- 延时双删如果失败, cache 数据不一致
解决: ==本质上要避免读流程把脏数据写入 cache== 对每一笔数据启用一个 **开关**
==写缓存禁用==机制:
- 每当有**写流程到达时，先将该笔数据的“开关”关闭，然后正常执行后续流程，执行完成后再重新将“开关”打开**
- **在“开关”关闭期间**，所有到达的读流程正常执行步骤，唯独**不会在读 db 后执行写 cache 操作**
- 写流程完成写 db 操作后，**延迟一段时间**再重新开启该笔数据下的 “写缓存机制”
### 更新数据库+删除缓存
最优 **缓存的写入通常要远远快于数据库的写入**
==如果删除缓存时失败, 会出现短暂数据不一致(依靠过期时间兜底)==
解决:
- 引入事件驱动 消息队列重试删除操作
- 订阅 MySQL binlog
## 消息队列/事件驱动 (最终一致性终极方案)
这是在微服务架构下保证最终一致性的**最可靠和最解耦**的方案, 它利用了你在电商项目中使用的**RabbitMQ** 或其他消息队列.
- **写操作**:
    1. 应用更新数据库.
    2. 在**同一个本地事务**中, 向一个专门的**事务消息表**里插入一条消息.
    3. 一个独立的后台任务会扫描这个消息表, 将消息投递到**RabbitMQ**.
    4. 所有需要同步数据的服务(比如缓存更新服务)订阅这个队列.
- ? 为什么不直接在事务中投递消息: 出错后消息无法撤回
- **或者使用Canal等工具监听数据库Binlog**:
    1. 应用直接更新数据库.
    2. 部署一个`Canal`服务, 它会伪装成MySQL的从库, 实时订阅主库的`binlog`(二进制日志).
    3. 当`Canal`监听到数据变更时, 它会将变更消息发送到**RabbitMQ**.
    4. 缓存更新服务消费消息, 然后**删除**对应的Redis缓存.
- **优缺点**:
    - **优点**: **高度解耦**, 更新数据库的业务代码完全不需要关心缓存的存在. **可靠性极高**, 基于数据库日志或事务消息, 保证了消息不会丢失, 从而保证了缓存的最终一致性.
    - **缺点**: **架构复杂**, 需要引入并维护消息队列和/或Binlog订阅工具. **一致性有延迟**, 从数据库更新到缓存失效, 中间会有毫秒到秒级的延迟.