- 吞吐量:单位时间内系统处理的请求数 QPS TPS
	- 影响: CPU, 内存
- 响应时间: 客户端从发起到收到响应
	- 网络延迟, 排队延迟, 处理耗时
- 并发数: **同时被系统处理的请求数量**
	- **平均并发数 ≈ 吞吐量 × 平均响应时间**
	- 连接池大小, 线程/协程数, 请求积压

> 微服务的响应时间在高峰时段突然变慢，但 CPU 和内存使用率都正常，你将如何排查？
- 定位
	- 是全局变慢, 还是局部
	- 如果只有 P95/P99, 可能是尾部延迟问题
- 排查
	- 是不是业务处理变慢
		- 下游依赖慢：SQL 慢查询、下游服务响应慢。
		- 热请求过多：某些请求的处理逻辑复杂，比如要扫描全表的请求变多。
		- 锁竞争：mutex 热点冲突
	- 是否有排队延迟 
		- Goroutine 阻塞/排队：Goroutine 数量变化，是否堆积、是否泄漏
		- 连接池耗尽：DB/Redis 等连接池打满
		- 限流：下游服务对自身服务进行限流
		- 队列积压：生产/消费速度不匹配
  - 网络延迟：确认是否是网络层的问题
    - 服务跨区：存在跨机房的请求（跨国业务更常见）
    - 网络抖动：服务间调用的 RTT 指标
    - TCP 拥塞：丢包重传、连接超时
- 工具辅助
	- 处理时间：分布式调用链 tracing、日志、下游响应时间。
	- 排队延迟：
		- pprof 查看 goroutine profile、heap、mutex profile 等状态。
		- runtime 查看 GC 时间、goroutine 数量等指标。

- 高并发
- 高吞吐
- 低延迟
- 高可用