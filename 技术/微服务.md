# 服务注册 服务发现
让 Client 端根据服务名找到 Server 的地址
不用 DNS:
- 多级缓存, 不能及时感知节点变化
- 不能注册端口, 只能注册 HTTP
**引入 Registry**
## 服务上线
- Server 启动后，向 Registry 注册自身信息
	- Registry 保存着所有服务的节点信息
	- Server 与 Registry 保持心跳，Registry 需要感知 Server 是否可用
- Client **第一次**发起 RPC 调用前，向 Registry 请求服务节点列表，并把这个列表缓存在本地
	- Client 与 Registry 保持数据同步，服务节点有变化时，Registry 通知 Client，Client 更新本地缓存
- Client 发起 RPC 请求，Server 返回响应
## 服务中心选型: CAP理论
- CP: 牺牲可用性, 保证一致性 Zookeeper, etcd
- AP: 牺牲一致性, 保证可用性 Eureka, Nacos, Consul
选型:
- 体量小时选CP
- 体量大选AP
	- 有大批服务节点同时上下线, 负载过高
	- 同步大量数据, 服务长时间不可用
## 识别服务节点可用情况: 心跳机制
[[交易处理平台#consul节点故障]]
- Server 每隔几秒向 Registry 发送心跳包，收到响应则表示服务节点正常，在指定时间内没收到响应，则判定为失败
- 注册中心发现某个节点不可用时，会通知 Client，Client 更新本地缓存的服务节点列表
- 发现心跳断了，Registry 立即通知 Client 某节点不可用，避免服务真的宕机时，仍然有请求发来
- Registry 继续向 Server 发心跳，如果发几次心跳都是失败的，才认为服务节点不可用。如果心跳恢复，再告知 Client 服务节点可用
	- 重试策略：先连续发几次心跳，过一定时间间隔后再发心跳，需要考虑重试次数和重试间隔
## Consul VS etcd
“这是一个很好的问题. 在这两个项目中, 我分别选用了 Consul 和 etcd, 这并不是一个随意的决定, 而是基于两个项目在**核心诉求**上的根本不同. 简单来说:
==Consul 的数据中心 (Server/Raft) 是 CP 的, 但它的客户端代理 (Agent/Gossip) 和读取机制是 AP 的==
- **城市生活服务平台 (Project 1)**: 它的核心是**大规模、动态的微服务治理**. 我更看重的是开箱即用的**服务发现、健康检查**和**生态的完备性**. 所以我选择了 **Consul**.
- **分布式缓存系统 (Project 2)**: 它的核心是**分布式状态的强一致性**. 我需要一个绝对可靠的元数据存储来维护缓存集群的拓扑和节点信息, 任何不一致都可能导致数据错乱. 所以我选择了 **etcd**. 

| 对比维度         | Consul (更适合: 服务发现与治理)                                                                                                                                                                                                                       | etcd (更适合: 强一致性元数据存储)                                                                                                                                                                                                                                                                                                                       |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **核心设计哲学**   | **"全功能的服务网格平台"**. 它是一个“瑞士军刀”, 内置了服务发现, 健康检查, K/V存储, 服务网格等所有你需要的功能.                                                                                                                                                                          | **"高可用的分布式键值存储"**. 它是一个“地基”, 专注于一件事并做到极致: 提供一个绝对可靠的、基于Raft协议的强一致性K/V存储.                                                                                                                                                                                                                                                                     |
| **CAP 定理取舍** | **AP (可用性优先)**. Consul 的架构设计更倾向于保证在网络分区发生时, 服务发现功能依然可用(尽管可能读到少量过时数据). 它通过 Gossip 协议在节点间同步信息, 这使得它对网络延迟不那么敏感.                                                                                                                                | **CP (一致性优先)**. etcd 严格遵循 Raft 协议. 在网络分区导致集群无法形成“多数派”时, 它会**拒绝写入**, 以保证任何时刻从集群中读到的数据都是强一致的.                                                                                                                                                                                                                                                 |
| **服务发现机制**   | **原生内置, 功能丰富**. 服务发现是 Consul 的一等公民. 它提供了 DNS 和 HTTP 两种接口, 并且与健康检查紧密集成.                                                                                                                                                                      | **基于 K/V 存储构建**. etcd 本身不直接提供服务发现接口. 你需要自己设计一套 Key 的格式(例如 `/services/my-cache/node1 -> ip:port`), 然后通过 Watch 机制来监听这些 Key 的变化, 从而实现服务发现.                                                                                                                                                                                                     |
| **健康检查**     | **非常强大和灵活**. Consul 内置了多种健康检查方式: **TCP, HTTP, gRPC, TTL, 脚本检查**. 并且它通过 Gossip 协议在集群中广播健康状态, 使得状态传播非常快.                                                                                                                                      | **相对简单, 依赖客户端**. etcd 本身不主动检查服务的健康. 它依赖于客户端通过**租约(Lease)**机制来实现心跳. 客户端获取一个租约(比如10秒), 然后不断续租. 如果客户端崩溃, 无法续租, 租约到期后, 与之关联的Key就会被自动删除.                                                                                                                                                                                                         |
| **应用场景分析**   | **为什么用在“城市生活服务平台”?**<br>1. **服务数量多, 动态性强**: 用户, 商家, 订单等众多微服务需要频繁上线, 下线, 扩缩容. Consul 开箱即用的服务发现和健康检查能完美地管理这个复杂的环境.<br>2. **可用性要求高**: 即使在网络有抖动的情况下, 我们也希望服务调用尽可能成功. Consul 的 AP 特性更符合这个要求.<br>3. **运维友好**: Consul 自带的 UI 非常直观, 便于查看和管理所有服务的状态. | **为什么用在“分布式缓存系统”?**<br>1. **元数据一致性是生命线**: 缓存集群的节点列表, 分片规则, 主从关系等元数据, **绝对不能出现不一致**. 任何一个节点对集群拓扑的认知有偏差, 都可能导致缓存数据被写到错误的地方. etcd 的 CP 特性提供了这种金标准的一致性保证.<br>2. **Watch 机制是关键**: 分布式缓存的节点需要实时感知其他节点的加入和退出, 以便进行数据迁移和拓扑重建. etcd 强大的 Watch 机制能让所有节点可靠地监听到元数据的任何变化.<br>3. **可靠的分布式锁**: 在进行集群拓扑变更或主节点选举时, 需要一个可靠的分布式锁. 基于 etcd 实现分布式锁是业界非常成熟和可靠的方案. |
**对于城市生活服务平台, 核心诉求是微服务架构下的高可用和服务治理.**
- 我们需要一个功能丰富的服务发现系统, 它必须具备强大的健康检查能力和良好的生态集成.
- 我们能容忍短暂的数据不一致 (比如一个节点刚下线, 别的服务在1秒后才知道), 但不能容忍服务发现功能本身不可用.
- 因此, **Consul 的 AP 设计、强大的健康检查和内置的服务网格潜力**, 使其成为我们这个项目的不二之选.
**对于 `ggcache` 这样的分布式缓存/存储中间件项目, 核心诉求是分布式节点间的状态同步和协调, 要求绝对的一致性.**
- 哈希环的拓扑信息绝对不能出现分歧, 否则整个系统的数据分布都会错乱.
- 我们愿意为了保证这份数据的绝对一致, 牺牲掉在网络分区下的部分可用性 (例如, 无法更新拓扑).
- 因此, **etcd 的 CP 设计和基于 Raft 的强一致性保证**, 是这类分布式协调任务的黄金标准.
# 负载均衡
属于客户端的工作
- 将请求均匀发给每个节点
- 优先发给相应最快的节点
## 分类
### 随机, 加权随机
请求量大, 各节点性能差异不大
### 轮询, 加权轮询
- 按固定顺序逐个访问
- 访问成功的节点权重增加
适合存在新老机器, 节点性能不同
### 哈希, 一致性哈希
哈希环
与本地缓存结合, 同一来源的请求映射到同一节点
适合不同客户端请求差异大, 需要用到本地缓存 / 节点增加, 减少
## 指标
- 最少连接
- 最少活跃
	- 已经接收但是还没返回
- 最快响应时间 
# 熔断
场景: 服务端出现问题
- 服务指标: 响应时间, 错误率, 连续错误数
- 硬件指标: CPU, 内层, 网络IO
目的:
- 为服务端恢复争取时间
- 避免全调用链路崩溃 (其他服务也堆积)
## 流程
1. Server 被监控到异常，触发熔断，熔断器抛出熔断的异常响应
2. Client 收到异常，利用负载均衡重新选择节点，后续请求不再打到被熔断的节点一段时间后，Client 再对这个节点重新请求，如果正常响应，则缓慢对这个节点放开流量，如果3.仍然是熔断，则继续执行 Step 2，如此循环
# 限流
## 静态算法
### 令牌桶
系统以恒定速率产生令牌并把令牌放到桶里，每个请求从桶里拿到令牌才会被执行，反
之被限流
### 漏桶
产生的令牌没被取走也不会积攒下来, **无法应对偶发性流量突变** 
### 固定窗口
固定时间段内只处理固定数量的请求
### 滑动窗口
随时间移动窗口
## 动态算法: BBR
### 原理
BBR 的名字已经揭示了它的两大核心指标：
1. **瓶颈带宽 (Bottleneck Bandwidth, `BtlBw`)**: 指的是一条网络链路中，吞吐量最低的那一段的带宽。这是决定你传输速率的“天花板”。
2. **往返传播时间 (Round-trip propagation time, `RTprop`)**: 指的是一个数据包从发送端到接收端，再回到发送端所需的最短时间（不包括在路由器中排队等待的时间）。

BBR 的目标就是找到一个理想的平衡点：**发送速率恰好等于瓶颈带宽，同时在途的数据量（inflight data）刚好填满整个网络管道（`BDP = BtlBw × RTprop`）**。这样既能跑满带宽，又不会在路由器中产生额外的排队延迟。
为了实现这个目标，BBR 的工作模式就像一个智能的探测机器人，它会周期性地进行以下探测：

-  **探测带宽 (`ProbeBW`)**: BBR 会在大部分时间里以它估计的瓶颈带宽速率发送数据。但为了确认带宽是否发生了变化（比如网络变好了），它会周期性地、短暂地**提高发送速率**（比如提高25%）。
    - 如果此时发现数据传输速率也跟着提升了，BBR 就知道瓶颈带宽增大了，于是更新 `BtlBw` 的估计值。
    - 如果速率没有提升，说明已经触及天花板了，多发的数据开始在路由器排队。
- **排空队列 (`Drain`)**: 在短暂提高了发送速率后，BBR 会立即进入一个“排空”阶段。它会短暂地**降低发送速率**（比如降低到之前速率的75%），把刚才因超发而积压在路由器队列中的数据包“排干”，从而降低延迟。
- **探测延迟 (`ProbeRTT`)**: 为了获得最准确的往返传播时间 `RTprop`，BBR 会周期性地进入一个探测延迟的状态。它会把在途数据量降到一个非常小的水平（例如只有4个数据包），持续一小段时间（如200毫秒）。这时测得的往返时间就可以认为是几乎没有排队延迟的 `RTprop`
通过在这几个状态之间不断地循环，BBR 能够动态、实时地跟踪网络瓶颈带宽和最小延迟的变化，从而调整出一个最优的发送速率。
### BBR 的优势
1. **高吞吐和低延迟**：在大多数网络环境下，尤其是在“长肥网络”（高带宽、高延迟）中，BBR 能在跑满带宽的同时，保持非常低的延迟。
2. **丢包不敏感**：它不依赖丢包来判断拥塞，因此在有少量随机丢包的网络中表现远超传统算法，不会轻易降速。
3. **快速启动**：启动时能更快地探测到链路的可用带宽，迅速达到高发送速率
## 流程
- 在中间件记录流量和阈值，并在中间件中实现限流算法。
- 对于偶发性的触发限流，只要在超时范围内 ，可以同步阻塞等待请求被处理。
- Server 的某个节点触发了非偶发性限流, Client 利用负载均衡调低该节点的权重，尽量少向这个节点发请求。
	- 区别于熔断的不再发请求，限流仍然会发请求，只是降低频率
# 降级
## 场景 & 目的
系统出现故障后的补救措施，或可预见的故障前的应对措施，来保证整体的可用性，
## 手段
- 考虑停用部分监控埋点、日志上报等观测类中间件
- 根据业务场景判断，停用边缘服务，返回服务繁忙之类的响应。
- 对于有缓存的接口，降级时只查缓存，不查 DB，没命中缓存则返回错误的响应
## 核心思想
- 如何判断节点的健康状态?是否需要熔断/限流/降级?
	- 通过监控看指标:QPS、连接数、节点负载等。
- 熔断/限流/降级后，怎么恢复?
	- 熔断限流搭配负载均衡，等节点恢复正常后，再重新选择。
	- 降级有时是手动恢复。
# 超时
在设置的时间段内, 如果请求未被处理, 直接取消
目的: 避免堆积大量请求连接, 影响新请求处理, 导致系统崩溃
**设置指标:** TP99, 99%的请求可以完成
针对不同的调用下游设置不同的时间
# 幂等
保证一个请求不被多次执行
场景: 请求的响应结果是超时, 可能有两种情况: 
- 服务端没处理(前方请求堆积，排不上队)
- 服务端处理了发送响应时，碰到了网络抖动导致超时
## 幂等去重
面对写请求, 服务内部重试时, 需要保证同一请求处理一次和多次的结果相同
方法:
- 请求方每次请求生成唯一的ID，在首次调用和重试时，唯一的ID保持不变。
- 服务端收到请求时，查询ID是否被处理过，处理过则直接返回结果，不再重复执行业务逻辑。