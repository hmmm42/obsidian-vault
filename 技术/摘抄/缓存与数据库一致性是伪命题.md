[缓存数据库一致性是伪命题，延迟双删？我还延迟八删？我列害不？_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1CS421d7fw/?vd_source=5cb802be4238079ffb5be845555a8162)
## 核心观点：缓存与数据库一致性是伪命题

视频主讲人认为，在讨论缓存时过度追求“一致性”本身就是一个伪命题 。一旦系统引入了缓存，就必然接受了数据在某个时间窗口内的不一致性。因此，讨论的关键不应该是如何实现绝对的“强一致性”，而是**业务可以容忍多长时间的不一致** 。
### 强一致性 vs. 最终一致性
* **强一致性**: 指的是任何时刻，缓存和数据库中的数据都完全一样。主讲人认为，在分布式系统中，绝对的强一致性几乎是不可能实现的，且成本极高 。
    * **系统层面的例子**: 无论是操作系统将数据写入硬盘（会经过缓冲区），还是CPU的多级缓存（L1, L2, L3），甚至硬盘本身都可能带有缓冲区。在断电等极端情况下，这些层级都无法保证数据的绝对强一致 。
* **最终一致性**: 不保证数据的瞬时一致，但承诺在一定的时间窗口后，数据最终会达到一致状态 。这是绝大多数互联网业务的现实选择，关键在于确定业务场景所能接受的“时间窗口”有多大（例如，100毫秒或2秒）。
## 对“延迟双删”方案的批判
主讲人对业界流传的“延迟双删”方案持强烈的批判态度，认为它并不能从根本上保证一致性 。
* **本质是概率游戏**: “延迟双删”的逻辑是删除一次缓存不成功，就过一段时间再删一次。这本质上是一种概率性的解决方案，并不能100%保证数据的一致性。第一次删除失败，第二次同样也可能失败 。
* **讽刺性的比喻**: 主讲人讽刺道：“你延迟双删，我优化一下搞个‘延迟八删’，是不是比你更强？” 这说明靠增加删除次数来提高成功率的方案是没有意义的，因为它没有解决问题的核心 。主讲人表示，自己在多年的工作中从未在实际生产中见过这种方案，认为它更像是一个为了面试而存在的理论 。
## 业务场景决定一致性级别
一致性的要求完全取决于业务场景的性质，不同业务对此的容忍度天差地别。
#### **一致性要求低的场景（可容忍最终一致性）**
* **视频播放量、评论数**:
    * 许多主流平台（如B站）对超过一定数量的播放/评论数会显示为“1万+”或“10万+”的模糊数字 。
    * 这样做部分原因是为了降低实现实时精确计数的巨大成本 。这类计数更新通常是**批量异步处理**的。例如，系统可以聚合1秒内的10万次播放请求，然后一次性写入Redis，而不是处理10万次单独的写入请求，这样性能会高得多 。
    * 在这种模式下，如果服务器在更新前宕机，最多会丢失这一秒内的数据。对于一个总播放量上万的视频来说，丢失少量播放数据，用户和UP主都难以察觉，业务上是完全可以接受的 。
* **动态配置下发**: 很多后台配置下发后，系统会提示“一分钟后生效”或“N分钟内生效”，这本身就是一种非强一致的体现 。
#### **一致性要求高的场景**
* **支付与金融**: 与钱相关的业务，一分一毫都不能出错。这类场景虽然也无法做到绝对的实时强一致，但必须通过对账、补偿等机制保证**最终账目的绝对准确** 。
* **用户状态和付费服务**: 用户的核心状态或付费操作（如购买粉丝灯牌）是不能丢失的，因为这直接关系到用户资产和体验 。
## 分布式事务：另一个“伪命题”
主讲人认为，分布式事务和缓存一致性类似，在很多场景下也是一个“伪命题”，大厂在实践中会尽量避免使用 。
* **成本高、性能差**: 实现分布式事务（如两阶段提交）的逻辑非常复杂，会严重拖慢系统性能，成本极高 。
* **“回滚失败”的死循环**: 分布式事务最大的难题在于回滚。如果一个事务需要回滚，但回滚操作本身又失败了，系统就陷入了“套娃”式的困境，难以处理 。
## 大厂的实践：最终一致性 + 补偿方案
既然强一致性和分布式事务都不可取，大型互联网公司普遍采用“最终一致性”的设计思想，并辅以强大的补偿机制来确保数据正确。
1.  **记录失败日志**: 当操作失败时，最重要的一步是记录日志。最稳妥的方式是**写入本地磁盘日志**，因为像Kafka这样的消息队列本身也可能崩溃。可以同时写本地日志并推送到消息队列作为双保险 。
2.  **监控与报警**: 日志记录下来后，通过监控系统发现错误，并触发报警 。
3.  **补偿与对账**:
    * 收到报警后，开发人员介入，根据失败日志进行**数据补偿**或**人工回放**操作，手动修正数据，保证其最终正确 。
    * **对账系统**是另一种常见补偿方案。例如，微博有对账系统，会监控博主发视频是否在10分钟内成功，如果超时未成功，系统会自动报警，以便在用户投诉前主动发现并解决问题 。
    * 许多大厂发生长时间故障后，所谓的“修复”过程，很多时候就是在**通宵加班搞数据**，即通过跑批、对账等方式进行数据补偿 。
## 系统设计中的其他权衡（Trade-offs）
* **RPC vs. HTTP**: 在高并发（如QPS上万）的内部服务调用中，应优先使用基于长链接的RPC框架，其性能远超基于短链接的HTTP（性能差距可能达十倍以上）。如果QPS不高（如几百到两千），使用HTTP也可以，但可能需要投入更多服务器硬件来弥补性能差距 。
* **日志的性能悖论**: 打日志是为了排查问题、保障系统可用性，但高并发下频繁的写磁盘（IO）操作本身就是巨大的性能瓶颈，甚至可能成为拖垮系统的元凶。异步打日志虽然能缓解主线程压力，但又可能引入日志堆积或线程过多的新问题 。
* **分布式锁**:
    * 基于Redis主从模式的分布式锁存在风险：如果锁信息写入主节点后，在同步到从节点前主节点宕机，新选出的从节点上没有锁信息，会导致锁失效 。
    * Redisson的红锁（RedLock）试图解决这个问题，但其稳定性在业界也存在争议 。
    * 在业务设计中应尽量减少对分布式锁的依赖 。