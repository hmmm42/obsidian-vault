## 一、 背景与问题
* **业务场景**：一家线上卖菜的新零售公司，因疫情封控导致流量暴增，系统频繁崩溃。
* **崩溃表现**：服务和数据库宕机，只能手动重启，但几分钟后又会再次崩溃。
* **核心矛盾**：在商品有限而用户暴增的情况下，一个普通的购买功能被强行变成了高并发的秒杀场景。
* **压力来源**：
    1.  用户疯狂**刷新商品页面**，导致对商品查询接口的流量洪峰。
    2.  开售后用户疯狂**点击购买按钮**，导致对下单扣库存接口的流量洪峰。
## 二、 核心挑战
1.  **读请求洪峰**：海量的商品信息查询请求，直接冲击数据库。
2.  **写请求洪峰**：海量的库存扣减请求，由于数据库**行锁**机制，导致请求串行处理，性能极低。
3.  **资源耗尽**：服务器的线程池和数据库的可用连接池被瞬间打满，导致整个系统“假死”。
---
## 三、 设计思路与优化九招（神功九式）
### 第一招：前端拦截与缓存 (甩锅给前端)
* **解决问题**：减少来自同一个用户的无效高频请求。
* **具体做法**：
    1.  **客户端缓存**：商品信息这类不常变化的数据，在前端进行短时间缓存，避免每次都请求后端接口。
    2.  **下单按钮拦截**：用户点击“购买”后，按钮置灰或禁用一段时间，防止用户因手抖或网络延迟而重复提交请求。
* **效果**：流量有一定降低，但服务器和数据库的根本压力依然巨大。
### 第二招：服务端内存缓存
* **解决问题**：彻底解决商品信息查询对数据库的压力。
* **具体做法**：
    1.  **预热到内存**：在 Java 服务启动时，将商品信息等几乎不变的数据，直接加载到服务本地内存中。
    2.  **不设过期时间**：让缓存数据与服务器“共存亡”。避免了使用 Redis 等外部缓存时需要处理的缓存雪崩、击穿等复杂问题。
* **效果**：查询商品信息的流量被完全阻挡在数据库之前，服务层可以轻松横向扩展来应对。但下单接口的数据库压力问题仍未解决。
### 第三招：限流 (令牌桶算法)
* **解决问题**：保护下游的数据库不被瞬时流量冲垮。
* **具体做法**：
    1.  **选用令牌桶算法**：它允许一定的突发流量（桶的容量），同时控制了整体速率。
    2.  **按处理能力限流**：假设数据库每秒能处理 20 笔库存扣减，则设置令牌桶容量为 20，并以每秒 20 个的速度生成令牌。
    3.  **无令牌则拒绝**：下单请求必须先获取令牌，获取失败则直接返回“服务器繁忙”，避免请求进入后端业务逻辑。
* **效果与局限**：
    * **优点**：服务器和数据库运行平稳，得到了有效保护。
    * **缺点**：用户体验差，大量请求被拒绝。更重要的是，秒杀变成了“慢杀”（5万颗白菜，每秒20颗，需要40多分钟），商品可能卖不完。
### 第四招：Redis预扣库存 + 消息队列异步持久化
这是秒杀系统的核心，将对数据库的压力转移和分解。
* **解决问题**：数据库 `UPDATE` 操作的行锁是性能瓶颈。
* **具体做法**：
    1.  **库存预热到 Redis**：将商品总库存提前加载到 Redis 中。
    2.  **Redis 内存扣减**：下单时，直接在 Redis 中执行 `DECR`（减一）操作。Redis 基于内存，单机 QPS 可达10万，性能极高。
    3.  **发送消息到 MQ**：Redis 扣减库存成功后，发送一条消息（包含用户ID、商品ID等信息）到消息队列（Message Queue, 如 RabbitMQ, RocketMQ）。
    4.  **异步消费**：由独立的消费服务从 MQ 中拉取消息，进行后续的数据库持久化操作。
    5.  **优化：更新转插入 (Update to Insert)**：持久化时，不再是 `UPDATE` 库存表，而是直接 `INSERT` 一条库存变更记录。`INSERT` 操作比带行锁的 `UPDATE` 快得多，因为此时防超卖的逻辑已经由 Redis 保证了。
* **兜底机制（保证数据一致性）**：
    * **问题**：如果在 Redis 扣减成功后，发送消息到 MQ 的步骤失败了怎么办？
    * **方案**：使用 **Lua 脚本** 保证 Redis 操作的原子性。
        1.  在 Redis 扣减库存的**同时**，将本次下单信息（如订单ID、时间戳）存入 Redis 的一个 `Set` 集合（暂存区）。
        2.  MQ 消费者成功消费消息并落库后，再从这个 `Set` 集合中删除对应的下单信息。
        3.  启动一个后台定时任务，扫描这个 `Set` 集合。如果发现某条数据已经存在超过 N 秒（如5秒）还未被删除，就认为消费失败，**重新向 MQ 补发消息**。
        4.  **消费者必须保证幂等性**，以防止重复消费消息。
### 第五招：批量消费
* **解决问题**：进一步提升 MQ 消费和数据库写入的性能。
* **具体做法**：消费者一次性从 MQ 中拉取一批消息（例如1000条），然后在内存中聚合，最后**批量 `INSERT`** 到数据库。
* **效果**：性能提升百倍以上，极大提高了数据落库的效率。
### 第六招：库存拆分 (分片/Sharding)
* **解决问题**：应对老板的担忧：“Redis 也是串行扣减，如果单点压力过大怎么办？”
* **具体做法**：将一个商品的总库存拆分成多份，存放在不同的 Redis Key 中。例如 5 万库存，拆成 5 个 Key，每个 Key 存 1 万。当用户下单时，**随机路由**到其中一个 Key 上进行库存扣减。
* **效果**：将单点的写压力分散到多个点上，进一步提升了 Redis 能够支撑的并发上限。
### 第七招：LVS 负载均衡
* **解决问题**：业务服务优化后，作为流量入口的负载均衡器（如 Nginx）成为了新的性能瓶颈。
* **具体做法**：使用 **LVS (Linux Virtual Server)** 替换 Nginx。
    * **原理**：LVS 工作在网络四层（传输层），而 Nginx 工作在七层（应用层）。LVS 只做流量转发，不做复杂的 HTTP 报文解析，因此性能极其强劲，单机可支撑百万并发。
    * **优点**：Linux 内核自带模块，集成方便。
### 第八招：DNS 轮询
* **解决问题**：如果单个 LVS 节点也扛不住流量怎么办？
* **具体做法**：在 DNS 服务商处，将一个域名配置**多个公网 IP 地址**，每个 IP 对应一台 LVS 服务器。
* **效果**：客户端访问域名时，DNS 服务器会轮流返回不同的 IP 地址，从而将流量分发到不同的 LVS 入口，解决了单点 LVS 的瓶颈。
### 第九招：动静分离 (CDN)
* **解决问题**：业务服务的网络带宽成为瓶颈，因为商品图片、视频等静态资源和动态业务请求占用了同一张网卡。
* **具体做法**：将所有静态资源（图片、视频、JS、CSS文件）全部托管到 **CDN (Content Delivery Network)** 上。
* **效果**：
    1.  用户从最近的 CDN 节点加载资源，**加速了访问速度**。
    2.  业务服务器的**带宽压力得到极大缓解**，可以专注于处理核心的动态 API 请求。
---
至此，通过这九招，一个能够应对高并发的秒杀系统便设计完成了。