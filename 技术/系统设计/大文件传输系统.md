## 大文件传输系统设计方案

### 1\. 需求分析 (Requirements Analysis)

#### 1.1. 功能性需求

  * **文件上传:** 支持单个大文件 (例如 \>1GB) 的上传.
  * **文件下载:** 支持已上传大文件的下载.
  * **断点续传:** 上传和下载过程可以被中断和恢复.
  * **数据完整性:** 保证上传/下载后的文件与原始文件完全一致.
  * **秒传:** 如果服务器已存在相同内容的文件, 用户可以瞬间完成上传.
  * **文件管理:** 提供查询文件列表和删除文件的基本功能.
  * **用户认证:** 只有授权用户才能上传和访问文件.

#### 1.2. 非功能性需求

  * **高性能:** 尽可能利用客户端和服务器的带宽, 传输速度快. API 响应延迟低.
  * **高可靠性:** 传输过程稳定, 数据不丢失, 不损坏. 系统能长时间稳定运行.
  * **高可用性:** 系统没有单点故障, 即使部分服务器宕机, 整体服务依然可用 (例如, 达到 99.9% 可用性).
  * **高扩展性:** 系统应能水平扩展, 以支持未来更多的用户和更大的存储需求.
  * **安全性:** 用户身份需验证, 传输过程和存储的文件都应被加密.

### 2\. 核心指标估算 (High-Level Estimation)

假设系统需要支撑以下规模:

  * **日活跃用户 (DAU):** 100 万
  * **日均上传文件数:** 1 万 (假设 1% 的用户每天上传一个文件)
  * **平均文件大小:** 2 GB
  * **读写比:** 1:1 (上传和下载次数相当)

**计算:**

  * **每日新增存储:** 1 万文件 \* 2 GB/文件 = 20 TB
  * **每月新增存储:** 20 TB \* 30 ≈ 600 TB
  * **每日上传 API 调用量:**
      * 假设分片大小为 8MB, 一个 2GB 的文件有 256 个分片.
      * 每次上传需要 1 (初始化) + 256 (上传分片) + 1 (完成) = 258 次核心 API 交互.
      * 总调用量: 1 万文件 \* 258 ≈ 258 万次/天.
      * **平均上传 QPS:** 258 万 / (24 \* 3600) ≈ 30 QPS. 峰值可能达到 10 倍, 约 300 QPS.
  * **总带宽:**
      * 每日总流量: 20 TB (写) + 20 TB (读) = 40 TB.
      * **平均所需带宽:** 40 TB / (24 \* 3600s) \* 8 (bits/Byte) ≈ 3.7 Gbps. 峰值带宽需求会更高.

**结论:** 存储增长快, 必须使用可扩展的存储方案. API QPS 不算特别高, 但对带宽要求很高, 必须将数据流和控制流分离.

-----

### 3\. 系统架构设计 (System Architecture)

我们将采用**控制流与数据流分离**的架构. API 服务器处理元数据和业务逻辑 (控制流), 而实际的文件数据 (数据流) 则直接在客户端和对象存储之间传输.

**组件说明:**

  * **客户端 (Client):** 浏览器, 桌面应用或移动 App. 负责文件分片, 哈希计算, 并发控制 (协程池), 断点续传逻辑和与服务端的 API 交互.
  * **负载均衡/网关 (LB/Gateway):** 系统入口, 负责流量分发, SSL/TLS 卸载, 鉴权等.
  * **API 服务集群 (Stateless):** 核心业务逻辑层. 处理文件的初始化, 完成, 秒传, 查询等请求. 它是无状态的, 便于水平扩展.
  * **元数据数据库 (Metadata DB):** 使用关系型数据库 (如 PostgreSQL, MySQL) 存储文件的元信息, 如文件名, 大小, 哈希值, 分片信息等.
  * **缓存 (Cache):** 使用 Redis 缓存热点文件的元数据, 或上传过程中的状态信息, 降低数据库压力.
  * **对象存储 (Object Storage):** 存储文件分片和最终合并的文件的物理位置. (如 ==MinIO, Ceph, 或云服务 AWS S3/GCP GCS==). 这是数据流的目的地.
  * **任务队列 & 合并服务 (Task Queue & Merge Service):** 用于处理异步任务. "完成上传" 的请求会向队列中添加一个文件合并任务, 由独立的合并服务来执行, 避免阻塞 API 服务.

-----

### 4\. 核心流程与 API 设计

#### 4.1. 上传流程 (Upload Workflow)

1.  **(客户端) 准备阶段:**

      * 用户选择文件.
      * 客户端计算整个文件的哈希值 (如 SHA-256).
      * 客户端将文件按固定大小 (如 8MB) 切分为多个分片.

2.  **(客户端 -\> API) 初始化上传:**

      * 客户端调用 `POST /uploads/initiate` 接口, 携带文件哈希, 文件名, 总大小等信息.
      * **秒传检查:** API 服务首先根据文件哈希查询数据库. 如果文件已存在, 直接返回成功, 完成"秒传".
      * 如果文件不存在, API 服务在元数据数据库中创建一条记录, 生成一个唯一的 `uploadId`, 并返回给客户端. 如果是断点续传, 此时可以一并返回已上传成功的分片列表.

3.  **(客户端 -\> 对象存储) 并发上传分片:**

      * 客户端根据需要上传的分片列表, 使用协程池并发上传.
      * **【关键优化】使用预签名 URL (Pre-signed URL):** 客户端为每个需要上传的分片向 API 服务请求一个预签名 URL (`GET /uploads/{uploadId}/chunk/{chunkNumber}/url`). API 服务生成一个有时效性、带授权签名的 URL, 该 URL 允许客户端将分片数据直接 `PUT` 到对象存储, **流量不经过 API 服务**.
      * 客户端拿到预签名 URL 后, 直接向对象存储上传分片数据.
      * 对象存储成功接收后, 客户端标记该分片上传成功.

4.  **(客户端 -\> API) 完成上传:**

      * 所有分片上传完毕后, 客户端调用 `POST /uploads/{uploadId}/complete` 接口.
      * API 服务验证所有分片是否都已在对象存储中存在.
      * 验证通过后, API 服务向任务队列 (如 RabbitMQ) 中放入一个"文件合并"任务.
      * API 服务立即向客户端返回"上传成功"的响应.

5.  **(合并服务) 异步合并:**

      * 合并服务从队列中获取任务, 调用对象存储的特定 API 将所有分片按序合并成一个最终文件.
      * 合并完成后, 更新数据库中文件的状态为"已完成", 并可选择性地删除临时分片文件.

#### 4.2. API 接口定义

  * `POST /uploads/initiate`

      * Request Body: `{ "fileName": "video.mp4", "fileSize": 2147483648, "fileHash": "sha256-hash-string" }`
      * Response: `{ "uploadId": "unique-id", "uploadedChunks": [1, 2, 5] }` or `{ "status": "completed" }` (秒传)

  * `GET /uploads/{uploadId}/chunk/{chunkNumber}/url`

      * Request: (No Body)
      * Response: `{ "uploadUrl": "pre-signed-s3-url" }`

  * `POST /uploads/{uploadId}/complete`

      * Request Body: `{ "chunkHashes": [{"number": 1, "hash": "md5-of-chunk1"}, ...] }` (分片哈希列表, 用于服务端最终校验)
      * Response: `{ "status": "success", "fileId": "final-file-id" }`

-----

### 5\. 数据库设计 (Schema Design)

**`files` 表 (存储最终文件信息):**

  * `id` (PK)
  * `file_name` (VARCHAR)
  * `file_size` (BIGINT)
  * `file_hash` (VARCHAR, UNIQUE) - **为秒传建立索引**
  * `storage_path` (VARCHAR)
  * `owner_id` (FK)
  * `status` (ENUM: 'completed', 'deleted')
  * `created_at` (TIMESTAMP)

**`upload_sessions` 表 (存储进行中的上传任务):**

  * `id` (PK, 即 uploadId)
  * `target_file_id` (FK, files.id, initially NULL)
  * `file_name` (VARCHAR)
  * `total_size` (BIGINT)
  * `chunk_size` (INT)
  * `total_chunks` (INT)
  * `status` (ENUM: 'pending', 'uploading', 'merging', 'completed', 'failed')
  * `created_at` (TIMESTAMP)

**`upload_chunks` 表 (存储已上传分片信息):**

  * `id` (PK)
  * `upload_id` (FK, upload\_sessions.id) - **建立索引**
  * `chunk_number` (INT)
  * `chunk_size` (INT)
  * `storage_path` (VARCHAR) - 分片在对象存储中的路径
  * `status` (ENUM: 'uploaded', 'verified')
  * UNIQUE INDEX (`upload_id`, `chunk_number`)

-----

### 6\. 部署与运维 (Deployment & Operations)

  * **可扩展性:**

      * API 服务是无状态的, 可以放在一个 Auto Scaling Group 中根据 CPU 或内存负载自动扩缩容.
      * 元数据数据库可以通过主从复制、读写分离来扩展读性能. 数据量极大时, 可考虑分库分表.
      * 对象存储、缓存、任务队列等都选用支持集群模式的分布式组件.

  * **高可用性:**

      * 在负载均衡后部署多个 API 服务实例.
      * 数据库采用主-备或主-主架构, 实现自动故障转移.
      * 对象存储配置多副本策略, 保证数据高持久性.
      * 服务跨可用区 (Availability Zone) 部署, 防范机房级故障.

  * **监控告警:**

      * **业务指标:** 上传成功率, 秒传命中率, 平均上传速度.
      * **系统指标:** API 延迟, QPS, 错误率, CPU/内存使用率.
      * **资源指标:** 数据库连接数, 存储容量, 网络带宽.
      * 建立完善的日志系统和告警机制, 对异常情况 (如上传失败率激增) 及时响应.